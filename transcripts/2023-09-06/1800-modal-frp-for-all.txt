                >>AMOS ROBINSON: Okay let's begin. Patrick is going to talk about Asynchronous Modal FRP.-- and Modal FRP for all: Functional reactive programming without space leaks in Haskell. We have two talks from him. But the first one is about Modal FRP. 
                >> PATRICK BAHR: In this first talk I want to present an implementation of a modal FRP language is a linkage embedded in the Haskell. So that is the full part of the type of the title. So I went to start by extending what I mean by Modal FRP. So the core idea of the function of this programming is that we want to do function programming with signals as first-class values. And so we can think of these signals as time varying values. We want to manipulate. So we think of them as devoting a function from time to values like this here. The signal of floating-. Numbers is really a function from time to floating type numbers. What I want to manipulate them in the usual function programming anyway. We have company nears that define the higher order functions that we define to instruct these signals and compose them and manipulate them. For example, in that function like this, we would used to manipulate the signal by subtracting one for example.
                 Okay so let's see, the court idea of functional vector programming. --functional FRP programming. So the question we raise is how do we actually represent these different kind of signals? There is different ways of doing this. I will just show you one. As this co-inducted the definition of streams. The stream consist of two parts, the head of the stream which is the value of the signal now. And then the here is the future state of the signal.
                 And so with this kind of na√Øve encoding we run into at least two problems. We might be able to write programmes that are not causal. They are sort of broken in a very bad way. Because they define a signal whose value now might depend on another signal value of another signal tomorrow. And so we actually can't run this, these programmes. So should definitely avoid these like this clairvoyance function that just throws away their head and just immediately returns them to the future state of the signal. That is a big no-no. Another problem is kind of the opposite that we sort of allow too much memory that we sort of look too much back into the time. And that will lead to space leaks. Like this leak function down here. Which takes a stream. And far into the future and it replicates the stream and in every step of this new stream of streams that we define. So in order to actually run a stream like this we would have to buffer at every step, every sort of the whole history of the stream. This will eventually run out of memory. S we want to avoid programmes like this. And so the different ways of avoiding these. And one is to use these moral type VI we basically take LTL leaning time logic to capture the passage of time in our functionality active programmes. And this goes back to 2012. Jeffrey. And we were able to use this types like here this type of a. Available in the next type time set up. Later modality from LTL, this type a is only a verbal the next time step. So we say something about also when the data is available. Now we go ahead and take our type of signals, streams here, as the representation. And insert the amount of sleep modality to really express this temporal dependency. And say okay the future state of this stream is of able only in the next time step. So now if we unfold this co inductive definition we really see how time of this stream evolves over time. How we have a value of the type a and the beginning and then the time passes, so later. And then we get new value of type A and so on. And so on. And this is how the streams and that mixtures that are typing rules and programmes are causal and that they don't have space leaks. And all right we can do this with a link was like this. Another question is, we also embed this in the mainstream language no Haskell?
                 And this has been a very successful approach in lamenting functional interactive programming linkages. So to shallow we embed this and say Haskell, to get sort of a whole, system of this language by seamlessly integrating with the host language. This is been very successful for our thing which is like Yampa, the approach they take, in instead of taking the signals as the primitive. They take signal functions as primitives. So we can only define signal functions and then show that you cannot write any of these bad signal functions that are not causal for example. A different approach is carried by FRP now you still have access to divine these signals as primitives. But the library only explored some of the category selected set of commentators. And make sure that the only signals that you can produce, our close will and don't need memory. This work for this like for Modal FRP. Is type A s, it is more difficult to embed anything like this. In the language like Haskell. It relies on rather interesting rules. The type of rules. So that are rather nonstandard. Sorry example you might have or like this. Which might seem odd right? Just because my heavy variable letter X in the context gamma doesn't mean that we were allowed to use it. It might seem silly but think of this variable X might refer to a value in the future. So we better not use it now. And to avoid non causal programmes. What might refer to a value from the past and so by using it now that we run the risk of leaking memory.
                 So we have to find a way of doing this. And this is what we did with this language reference Rattus which is implementation of the model of appealing which embedded in the Haskell. So let's what I want to represent to you today. And is based on that solid foundation. So based on the core calculus. Which we also have formalizing in  coq, log in all of these operational properties that we want to have in this language. So the limitation itself is based on this very simple observation. We also rely on a compiler plug-in that checks these type of rules. The restricted type of rules for the Rattus and rejects all those Haskell programmes that are not Rattus. So the Rattus implementation consist of these two parts. The Haskell library and also a compiler plug-in. All right. So the goal really for this, this project was to have a Modal FRP language that we can play around and experiment with. And a software ecosystem so this was the motivation for this work.
                 So that me show you how this thing which actually looks like. So this is how you would define the how you would write a Haskell programme is just  standard programme and then some modules like the first one here we import Rattus language essentially the stream library we can work with streams. Then down here we have element with this increment. Stream function with it takes the stream as input and then just increments with all the values it. And you can see we sort of seamlessly interact with the Haskell news the types from Haskell infections that are in their. In the standard library. So without any Haskell. So for this work we have to sort of say okay this is actually we want to programme the Rattus so we enable this in compiler plug-in and then we down here what we see is this in function should be type shaped as a Rattus from rather than just playing Haskell. So that's how you would interact with the system.
                 So here we have copy the function Inc. To look more will see in how the function actually works. So what we do here is to take a stream S as an input. We do the pattern matching on. We take apart the head of the stream and the tail of the stream. So the tale is a tape later, the stream event. And then we produce a new stream over here. And the head is easy enough, just adding one, two to ask and then we have to produce something later something. And this is where the delay comes. The delay is the induction form for the later modality. So what we do is it takes a term of type a and delays it and produces something of the type a. But it inserts this particular into the context. This is the pitch style that I mentioned earlier. So what it essentially does is it says now this key has to be typed in this new context. And this tick here, is essentially evidence that time has passed. And the clock has ticked and the letter T can make use of that. And general the context gamma may contain several of these. Right? For example here in example that we have, we have first AMB on the context and then we have C in the context and so on and so on. In particular here letter E is three times steps younger than letter B over here because of the three ticks and between. That's we keep track of the age of the variables in the context. And we can use that fact that we have the takes in the context we want to go back in time. So that is what we do with advanced that the advances the inverse of delay. So what it does is take something of type letter a and it is something that should be executed and later step. And it uses it in the future and get something of type E. And it can only do that if we know it knows that we are already in the future. We are already in the future for which this T was meant to be executed. So we advance or consume this and it forgets in particular it forgets all the stuff to the right of it. This refers to the data that was circulated in the future. And now we are going to go back with a in the future. So we use that down here with the definition of Inc. To produce this argument to the ink function that has to be a type stream of it. And the X axis of type stream of it. And it makes use of the fact that the delay has introduced tick the two the context.
                 All right so this is how we interact with the circle the modality in the Rattus. And that's not the whole story. We also have to be careful about the memory leaks as one of the motivations. This function here, it looks innocuous, this construction. What it does is takes an argument of type letter a and just produces a constant stream that just replicates an argument over and over again just constant stream. It looks rather innocent but you should not allow is to type check because it will actually leak memory. In particular, if A is something time variant that is a signal like a stream. It was actually the same function that I had earlier in the slides that I called Leakey, where I specialise the type here to a stream type. The problem is if it something like the stream and I push it in the future, this will leak memory. So we should not allow a function like this. And how do we type system prevent this? Well remember this is the type you will hear for the delay and it serves as a check into that context. Saying that the time has passed. Let's look at the typing role for the parable structure. What it means now here on the X has to type check in this context. That contains the X in the context and also a ticket took and that the time has passed. And this won't touch it. Because this is now the variable introduction rule and Rattus. So we can use the variable letter X that appears in the context. But only if either there is no check to the right of it. So no check to the right of it, that is not true here.  And that cheek to store memory over time. Something that is not time-dependent. And something like base types, product types and particularly not the later modality so. So anything that is not time-dependent. And we don't know that letter a is the stable type. So that is why we cannot use E here. Neither of the two conditions is fulfilled. And the idea is we should not move letter X into the future if we don't know that it is of the stable type. What we can do instead is rely on Haskell's tech class mechanisms. And say A) it better be stable type, the type checks, so we can give this construction this type with the constraint that letter E is stable. So this works now. So the stable types will ensure that our programmes will leak memory.
                 But is also whether research of because it rules out some programmes that you rather one it to write. So the map doesn't work anymore. Which is early too bad. And the problem is that function types are not stable. And what are they not stable? Well, what the values of the function type. They are closures. And that is closures might contain values of arbitrary type, particularly not stable type. So we should not allow these values to be moved arbitrarily into the future. So that is why they are unstable. But the problem is if letter F here is of the non stable type we cannot use over here because it is in the future, it like it is underneath the delay. So there is a check between the occurrence of letter F when it is bound and letter F when is used. And time has passed. So we are not allowed to use it. But we can turn type letter a into a stable type. Using this box modality. Now box again taken from LTL. So I think of box a in the type that classifies all data. That is available now any time in the future. Since the always modality. So we can try to turn T of Taipei into the type box a. And then always stable. So box letter E is always stable type. And then we require the T be type trackable in this, in this revised contact scam a box. And this is basically what the camera box is taking gamma and stripping all the stuff dynamic parks that is unstable. It's all variables of non-stable types and all the tics. So there's nothing temp oral in their. So that's the stable stuff remains in their. Right, so this idea of the boxing values. Now we change the type signatures lightly and make this into a box type then this will work.
                 So we have now that F is of type, box letter E to letter B and is of the scope over here. And the only thing that remains is that we can actually use it. We are also able to on box values like this. So on boxes very simply, turns something of type box E into letter a and we can use this box function into an actual function that we can apply to an argument of X. So that is basically the language that the Rattus supplies. So we have a circle modality in any box modality.
                 And I had implement it a game in the sling was. A very simple game. It's like a paddle, that looks like this. So how does it work? Well it is just a Pong that is a function that takes a stream of inputs and just a keyboard inputs and produces a stream of a pair of a position that is a two-dimensional position at the position of the ball. And a floating-. Number. And then the position of the paddle it moves. Then just a function of the divining of the position of the paddle like this. And the function of the defining the position of the ball like this. And we just zip them together. Up here, the two things, right and is you can see the position of the ball depends on both the input that we give. Because we might want to reset the game. And sort of start from scratch also the position of the paddle. So it is very, sort of compact code. And uses lots of higher order function like map, scan, and zip resources in their. So there is also to programmes that you can write in this language.
                All right so how this is actually implanted? You might wonder. As I said the implementation consists of two parts. But is Haskell Library + a compiler plug-in to get the right language out. And the Haskell library itself is really simple. Because all you need to do is define the syntax of the language. Right? It defines our later modality, approximated by O and then the box modality and then just allegedly primitive for the leader and then corresponding in the box and the on box and that is it. And that's interesting type checking is done by the plug-in and similarly stable and is empty type class with no instances. And the plug-in will take care of implement in this. So all of this smarts are sort of in the implementation of the compiler plug-in. And to ask lane how this works, I will just show you a very much simplified overview of the compiler pipeline of the GHC. And you start over here with the Haskell source that gets parsed into the EST. And we type of check that into type annotated and AST. And into Haskell court and then you see some passes over here to supply the optimize and then from that it will generate be executed will code. Now that Rattus does, it hooks into. Parts. So these are the ones I highlighted here. And in the red, for example here during the type checking phase we also supply a custom constraint solver that check all the stable constraints. So checking that the types are stable if we require them to be stable. And the circumstances. Right. And then overhear we give a scope check of what it actually checks the stricter typing rules of Rattus. I'm sure that this is true. And that after the sugaring the two extra passes, the first one called single take it requires a little bit of explanation so the language I showed you remember you can have multiple ticks in the context and denoting the passage of time. And that's all nice and well if you want to programme, like you can sort of look ahead of several times in the future. But you want to actually -- you won't actually run these programmes. The are prone to memory leaks. So we cannot guarantee that you don't have these memory leaks if you have multiple ticks but you can always transform this multiple tick calculus into a single tick calculus and then it is safer memory leaks in the things and we was happening here. And then finally I haven't even told you about this semantics of Rattus. It turns out Rattus is a strict language. Which Haskell is very much not. And what is happening here is transmission of the Haskell court that is reduced to intermediate language into a form that respect the semantics of Rattus so there's actually strict by default and only the box and later modality is lazy.
                 Okay let me talk about the middle theory very quickly since I'm also running out of time. So as I said sort of the Rattus is based on a court calculus that we call lambda tick which are formalized in Coq that actually won't crash. And so for semantic soundness property, essentially proof of logical relation. We can derive the actual operational properties we are interested in, meaning causality and the absence of space leaks. These are the two problems that I mentioned in the beginning of my talk.
                 And we also prove productivity so that each computation step is terminating. All right.
                 I also want to talk a little bit about the operation semantics. But I will skip in the interest of time, I will skip over a bit. And the importance is though that it uses a store to store delayed computation's. Whenever we do a delay, we story and some kind of he. And this heap in the general can contain sort of two phases. A heap, that is stores computations that are delayed for the next time step, because it is the later heap and then the computations that are, that have been delayed previously and are now safely to be used now.
                 And the important bit of it is, this is how delay in advance interact with it but the importance of it this year. Is that whenever the time passes that whenever the clock ticks we move from a story that looks like this. This is the now heap and this is the later heap overhear to a heap that looks like this. So the later heap is promoted to the now  heap next so the next time heap that we can read from a and this next construction of the semantics itself is the construction has no leaks. And then the proof is really, merely showing that this won't crash. That is taking care by the semantics property.
                 To conclude, what else is there we can try it out Rattus, you can just do a --installer Rattus and then you can go off to the racism play along with the language. There's some more stuff about the a theory and how that works in the paper and then also leads more examples. And there is a FRP library tool for this kind of programming and I showed you with again. And there's also a Yampa style FRP library and implement it in Rattus. And so we can actually do sort of arrowised if FRP in this language and also more details in this language and that I showed you earlier. That's all I had. Thank you. 
                >>AMOS ROBINSON: Yes, good. And. 
>> There is one thing I did not understand their. You showed us the map function and you expend there was a problem because we have parameter letter F now, we need in the future. But we also have map now we need map in the future and yet you didn't do anything to enable us to use map later. 
                >> PATRICK BAHR: Excellent questions whenever you have defined functions can the global space like the top level functions, they will always be stable because nothing else in the context that might be time-dependent. So remember, this is how in order to make things stable, we box them. Here in the box and all it does is takes the context we are currently in and remove stuff from it. If you have a top level functions like map, there's nothing in the context. Other than the top level functions that are also stable. So top level functions are by default stable. So we can use them anywhere. 
                >>AMOS ROBINSON: Any other questions? 
                >> AUDIENCE:   I'm curious how do you actually check this box operation? 
                >> PATRICK BAHR: How do you check what?
                >> AUDIENCE:   How do you actually check this box? 
                >> PATRICK BAHR: The compiler login, but I do with the compiler plug-in is basically I traverse the ASD and then collect this context here. So things that are variables the around. And then whenever I want to titrate the box and then I just remove the offending stuff from that context. So I mean I have the ASD at hand in the compiler part. So there is no magic to it. I really just do what you would also do instead of a standard loan language traversing the type with the AST.
                >> AUDIENCE:   I have a question, have you thought about putting mutable references or mutable arrays, that would interact with the stability? 
                >> PATRICK BAHR: I have not at all thought about mutability, no, this is all pure. And actually it crucially depends on being pure. And so I showed you the, one of the steps in the end was this turning into a multiple take calculus to multi-take calculus this kind of lesson to programme transformations. And it depends on being pure. 
