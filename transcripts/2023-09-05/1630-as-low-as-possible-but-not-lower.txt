                >> NIKHIL: Hello, hello, check. Oh some words for captioning, how does that look? Functional programming. Lambdas. Ah. Functional programme for the world Andreas Rossberg's keynote is going to be amazing. Is the captioning working? Andreas Rossberg you might take your, that often so it doesn't kind of rustle against the microphone.
                 Is Andreas Rossberg's microphone on? 
>>  And so I can give you like a five-minute warning. So how long?
.
.
. 
                >> NIKHIL: Okay all right let's settle in. All right. Let's get started. Let's settle in. You can find your seats. All right. Welcome to the afternoon session of ICFP. It is my great pleasure to introduce Andreas Rossberg who will give the afternoon keynote Andreas Rossberg has done a remarkable variety of things across the spectrum of programming, both functional and not. Including working on module systems, parametricity. Working on the V8 engine. And most recently on web assembly areas one of the initial code designers. And co-edits the specification of WebAssembly and really excited to hear what you have to tell us today. Thank you Andreas Rossberg. 
                >> ANDREAS: Yes, thank you for the nice introduction. So if you could not already tell from the nondescript title and Nik introduction I want to  WebAssembly. What is and what this, has to do that. This boiler is quite a bit. You probably discover some familiar faces on the web. So what is it? Let's get over with that first. It is a virtual machine, that is the shortest answer. But unlike other virtual machines you probably have seen, one distinct feature is it is a low-level virtual machine. And I will, some of my talk will be about what that actually means. As a consequence of that is also a language independent virtual machine. It is what form independent as well. It has all of these nice properties of the portable deterministic. Has sandboxing and is an open standard. So is not proprietary at all. Everybody can just participate.
                 And yes so this is kind of a talk about the language if you want. And the language talk you usually expect to see some code. This is not a talk but like that, this will be more like an overview talk. And it is an assembly language, right? So was not really a thing that you want to like dive through any presentation.
                 So I will flesh one example of WebAssembly code at you. Case you have never seen it so you get like an idea. I will not go through it in detail. But just to point out a couple of things. So first of all the S expressions, great. Maybe I should say first what this is. I hope you believe me that this is basically a translation of this little see function it takes a range in an array of doubles and sums with the elements. And there is a couple things that you can perhaps see here. Make their is all these instructions and is a stack machine. So you have all of these stack instructions the operations are implicit.
                 And you have things like loop constructs, label binders, you branches to that label. We have definitions of functions so all of the codes organised into functions. And which have parameters, explicitly in these types, the parameters are type, that is important to, everything is typed. On top of it all everything is wrapped up in a module. So all of the WebAssembly comes in modules to have explicit imports and exports. So that is roughly it. What it is in a very first approximation.
                 I should also say something that is not and that might surprise you, because the name tells you otherwise. It is not actually a web technology. [Laughter].
                 So this name is from my perspective a historical accident. Right, it came out of where we started. And it was essentially way to sell through the management at this is something we should be working on. Because of the time at Google and Mozilla and Microsoft and Apple and those were the four big companies that were involved in the initial design. Management cared about the web and nothing else. At least the management that was responsible for the people doing this.
                 So this was a nice way to kind of frame it. But really we were really careful to not design in a way that is related to a web it all. That makes it in any way dependent on the web. Or any of its technologies. If you actually look at the official spec, I think the web word occurs exactly once and that spec. So instead we want to designs of that is more universal and can be used in all sorts of environments. And that indeed happen. So web so is obviously put down to more violent cloud computing and so on so forth. And that's usually we just say Wasm. And the fact that this universal kind of execution environment, one of the two main reasons for me to be involved in this project.
                 Which is why I cared about its. So here is my little secret. The reason that I got into this is because I am a PL guy. I like designing programming which is. I like implementing programming languages. I not so much like implanting coach generators and backhands and runtimes and all that stuff. So I thought, hmm, wouldn't it be nice if I help to find this very nice abstraction and then I just target. And then all other people that are much more smarter and more extremes with the stuff do the work underneath it and I never have to think about it again? So that was kind of like my secret ovation for working on this. I mean, had I known how much of my lifetime ultimately and set up using up, [Laughter] probably would have been able to implement ten back ends at that time. But I hope there is some edited value to the holding as well.
                 And the second big reason to explain the second big reason why I would want to be involved and got involved in this. I have to go back a few years. Into the nineties when I was an undergrad student and first encountered this book some of you may have seen it. Some of you might even recognise that this is the first edition. So that is how old I am. I think when I first encountered this, this was like shortly before the 97 version of Santa and MI came out. So this is around 96 or whatever. This is the definition of standard ML. And the first time I saw it, it blew my mind. This is like the formalized specification of an entire language. And at the time the only thing I knew was all of these prose definitions, hand wavy definitions of linkages that just hope they are saying somehow that is a proximally we think they are saying. And this took a complete Lee different approach and made every thing precise. And I thought have loosely this is what we should be doing. Why are we not do this? Why is not everybody doing this?
                 Later on the SML folks especially around Bob Harper to this further and actually managed to mechanize the whole thing. Which took some additional steps for type III and so on. But ultimately they had something they could mechanize and prove it sound and have machine verify proof that the whole thing makes sense. And for me that was a very strong integration for everything that I did after that. I really thought this is the direction I should be taking.
                 So with WebAssembly, when that started to happen it was finally the opportunity for me to put this into practise and demonstrate that they could actually do this in the mainstream, right? So the WebAssembly, very proud to say is actually fully formalized. And buy fully, I mean actually even more so than the definition of standard ML. I mean by fully from the very first bite that you saw in your source code to the very last bit of execution. There is no room for ambiguity or guessing Al. And not just that we have multiple mechanization. And those were not done by me, but by other people, particular Conrad, and the first one in Isabel and then Conrad and Philippa Gardners West and 13 did and that was very early on and Connor Isabel mechanization even was done before we officially realise WebAssembly. So here's a formal semantics of the WebAssembly as it looked in our PLDI paper.
                 So that is all of it on the left-hand side you see the operational semantics, all of it, ignoring the details of the numerics. But other than that it is complete. And is a complete type system validation as it is called. Not even two pages, right? So this shows to me how elegant these methodologies are the our community has developed. But that is just a paper you can say in academic paper. We try to take it further. And actually put this into the official specifications. So the WebAssembly specification, the official standard dot commit is centered around this formalization. So it includes everything that you just saw. And for accessibility reasons, people did not want to have something like the SML definition where you have only inference rules and that's completely opaque to everybody who has not studied PL. And what it contains is a pro specification that is overly equivalent and saying with a bit more handwaving the same thing as the rules. So this is how the standard official stock looks. You can see in here the rules and the rendering is a bit ugly here, I think this is the PDF version. But anyway, this is the typing this is execution and you see the former bits here nested somewhere, they are small and the rest is all the prose trying to explain the same thing in psuedo code cobalt or something. All right so this is what we ended up with and the prose here is essentially a manual text rendering of the formal rules which I did by hand. Right? And it blew up the whole thing from the two pages you saw before to roughly 200 pages.
                 [Laughter].
                 And + four political reasons the whole thing, I had to write the whole thing in lockdown and use the Sphinx tool to generate it. Which is something I would never recommend to anybody. So if you ever have to write a serious technical document got don't use markdown. It is a terrible idea and it doesn't scale it all. Especially if you have to put math in it.
                 So here is a screenshot of what the source code looks like and spec looks like. And you have lots of markup and lots of mass markup and that's nested and is just horrible. So that's why we have to maintain this whole thing as well. Not just write it. So first of all writing the prose as you can imagine is extremely laborious. Right? Like nailing down the formal rules took me may be a few days a week or something like that. Because it is actually pre simple linkage in many ways. But producing the prose took months. Right? Because it is just stupid manual typing in this super bubbles formed. And it is not just also that this was done once and now we are done with it. We all go with it and I mean we keep working on the specification and we keep adding new features. And every time we have to go through the same process. For every proposal, right? Because the requirement for the WebAssembly, there is a elaborate process for the WebAssembly extensions and proposals. And one of the requirements is you, the deliverables is that you extend the spec including both formal and prose rules. And all of the stuff also has to be code reviewed. So anything that changes goes through code review. The stuff is a nightmare to code review, for one, because LATEG is the later part in the spec is very hard to read and make sense of it if you do code review. And the prose is just silver bows and buried in the markup stuff and also puts you to sleep because it's so redundant and repetitive.
                 And a top of that, one of the things markdown is a super different friendly because it is layout sensitive. So did Saar your bread-and-butter when you are doing code reviews. So here is a screenshot of a very simple example of a diff on a spec. So you can read may be three of these pages. But when you have to read 30 you fall asleep. And this is actually rather good case.
                 So there are various proposals as I said. And the various ones that are already completed and that make up Wasm and they are also like 25 or more still active. That is the reoccurring problem. And these proposals range in complexity from a diff that is less known 1000 lines to diff that are hundred thousand lines. So some of that is test, 70% maybe. But there is still a substantial amount of the spec types involved there. And ultimately I have no trust that this code is read carefully. It is just impossible. Most of the code reviews that I have to do, but still is just like, all of this looks like manual labour, right?
                 And is not just the spec but it is also a reference interpreter that we have. So another deliverable for the proposal is that you have to extend the reference interpreter which is written in the OCaml which is a new feature. Which is another rendering of the formal rule. So I originally wrote the reference interpreter to basically be an executable version of the reduction and was the typing. So here's a screenshot of what that looks like so you have to write that as well. So that is what every proposal author has to deliver.
                 And then we have the mechanizations, they are not required as a deliverable for proposals yet. Your not quite there yet. We have been trying to use this is something that we can require. But in the current reality that is not something that you could. But still we want to keep these up today. In some form, so that also has to be done. So I already said, Coq one is also up to Iris. And also folks who are interested in the actor and lean on your Haskell version of that. So here's an example of the clock rendering, so again like the same thing in another language. So there always deliverables you have to produce. And when you do that mechanization, like you do that manually that you translate I don't paper rules into coq somehow and they have to model the right thing. And that's eyeball correspondence and you can roughly say okay that looks reasonable. You have no way of checking that in any more specific way.
                 So the language folks, right? Of course the thought that should come to your mind when you see this like that for is there should be something here. And I mean all of these problems were kind of obvious that we would run into them we started six years ago. 6 or seven years ago. But at the time I had no idea how else to do it. We didn't have attack, would have the resources, did not know our exact requirement for all of these things. So we just went with what we could do. And that is why we ended up.
                 But now it turns out all the stars have aligned, so half a year ago we had a dock stool on WebAssembly in the first dock stool some people came together and talked about this. And realized you know what, we could actually do it. So these are the people involved here. It was particularly Conrad and also Filipa and they have the expertise for a mechanism the WebAssembly specification and doing the soundness proves in all of that. And then it was Sukyoung and their team they had the expertise to do from a project called safe J *, which is a project that took the JavaScript spec, which is also written in these, psuedo cobalt super way a handy way, Diebel style. And actually run it again Eliza interpret it and construct an interpreter from it that could run parts of the test suite. So that's closely related to what we needed here. Although it's a bit kind of like inverted problem, but still like the whole experience of transforming between prose and the formalism. And is what we needed. So we decided we should try doing this. And the currently spectech, and the idea is to create an idea to create DSL for writing the WebAssembly spec. So this is supposed to be the single source and the should be easy to write and read and code review obviously. And transformable and all the previous formats and particularly including like a nice light attack rendering so it should contain enough formatting that you could generate it in a pretty looking like tech format. Also generating natural language for some definition of natural format. And so I'm sure that some of you are now like scratching your heads and thinking way a moment one thing that has been done before there's this project for example called ott/Lem, why don't use that? We looked at it and ultimately doesn't fit our use case and are various reasons were. But roughly is trying to solve a much more general problem and this is much, much more complex. And the same time we cannot do everything that we need to. Like it doesn't understand some of our notation. Does not have any domain specific knowledge. That turns out that we want to use in some places. And we cannot just hack on it when we want to add like new special things.
                 And then there is the whole social thing of what is this long-term spec perspective on that? We need something, I mean this is industrial technology, it is industrial specification. And we need something that we know is still available in 20 years.
                 And if it is no longer maintained at least we would have to be able to maintain it which is not clear at all for project like that.
                 So ultimately we decided to do our own thing. And just define a very specialized DSL. That is just for our use case. And that just makes it much simpler problem to solve because we can just hack in whatever we need. And ignore and cut corners for things that we don't care about. And we can just week anyway that we want. And we can maintain ourselves. That is important to. So here is like a couple of simple examples. This is how you would like to find the Wasm ASC in that language now. And you can generate some nice Latech and that is not too exciting at. This will be some typing words in the syntax that we are using and this is kind of one reason that looks a bit odd maybe this optimize for Jeff's, maybe like every promise on its own line and not layout sensitive stuff. But from this you can generate some very pretty looking inference rules. Here is the reduction semantics, so you can also generate nice mathematical definitions from that. But more importantly you can also generate the prose so this is what we can do now with that. You can see the former words in here as before on this other page that showed you but it also generates this prose these algorithms steps for expressing the same thing. It's also able to collate the rules that are related. And turn them into conditionals. It can do all the cross-references in the spec. So you don't have to write this by hand anymore. I mean is still rough now but I mean we are still like in the middle of it. It's super impressive and good-looking. Here is the part you can generate right now probably kind of bread that in the back. But you just know that it's there. There is also work in the actor backend. So there's a little back and yet. But there is also no OCaml in the back and yet but you can see how it's going and where it's going. So the big pictures like we now have this one source of truth. In the toolchain is while we have this tool, it just passes and checks it and some generating, some intermediate representation and from that we can generate Lateg, the and generate the prose but of course we can generate the clock. But probably other things. Whatever we are interested in, interesting thing is now if we have proofs of coq the theory, it generates. And so basically we finish the porting of the proofs of coq the mechanization that we already have. The output of this thing that probably requires engineering so we haven't done that yet but once we're done with that. The proof run through. It is no longer just an eyeball correspondence. It comes from the same source. And there's just some machine transformation and between. Still of course have to trust all of these transformations there. But it is much less likely that you do weird things, weird mistakes. More interestingly to generate the prose, you have another internal representation. And the IR is more like declarative thing. And then there's the ER which is the  algorithm process that is reminiscent of animation. And when you write an interpreter for that, you can run the West and test suite against that. And when that succeeds, I think we are 98, 99 percent there, 100 now? Oh great, we are 100 now. So with that we actually have some validation that the prose and the spec make sense. Because the AR's is essentially AST for the prose. So altogether we hope this gives a much higher level of insurance higher level of the [Speaks Indigenous Language] them anything before. It was the first half of the topic either half I want to talk about the WebAssembly itself. Particularly what I mean by being low-level. So I say is a low-level language. What does that mean?
                 And there are various properties you could enumerate but kind of the slow that I want to give you that describes the best is it is a abstraction of the hardware, not a abstraction of the language. And that is a key difference to other popular VM's. When you look at the [Include File Not Found] they are essentially a relatively thin injection of Java or C #. Right? We are coming from down here and not from up there.
                 So that is very different. And the consequent so that is all of the linkages that are run on it are actually equal citizens. Like no linkage has any privilege there. They all just see something as the virtual hardware. And as far as I am concerned. This is really the only way to do a language, neutral, virtual machine. You have to be lower-level. Everything else will just lead you into whatever. So it is language neutral but it is also platform neutral. In the sense that you can embed it in any host environment that you want. It is just like it abstracts a little bit of your CPU. Right. And are actually by now I think almost a dozen different implantations of WebAssembly they could. And then that in your application, in your environment, whatever you want. So this is like a nice loan but what does it do more concretely, so more concretely, it's like virtual instruction set architecture. That is supposed to map more or less 1 on 1 instruction sites of actual hardware. At least in the first approximation of the WebAssembly one or that we were pretty close to that. An important characteristic as well is an a consequence of that is it has a very transparent and X licit cost model. So you always know what is going on we have a WebAssembly assembly and you know how you are running on you. And there are no hidden cause. So anything that should be totally explicit in the instructions that. And the slowing here is that comes with the predictable performance. So you really want to know what is going on the machine level. And the other part of it is, there is no such thing as an object model at all. So you have memory. But anything you need to build in terms of terms related to your language, you have to model yourself.
                 And is also assumed that the VM can be pretty simple because all, more interesting optimizations have already been performed by the producers. So the compiler generating assembly. The engine doesn't have to do anything clever or fancy at all and it runs your code. And it still has to do ditching, because has to translate the byte code to every native code you are running on. But that jit can be free straight forward and done. And it can be done ahead of time because you are not relying on any kind of dynamic optimizations or recompilation techniques like that are popular in modern VM's. So this is the general idea but to what extreme can you do that, right? How low can you go, and you have to make some compromises. So we are always operating this like triangle of conflicting goals with performance and simplicity. And generality or actually it's a cheeky girl of conflicting goals. Because hovering above all of them is like safety. And with that portability as the one thing that you can't compromise on. Has to be saved, we have to do in many ways that remain safe. And balancing these constraints sometimes just the Tates raising the abstraction boundary relative to what you have on real hardware because real harbor doesn't care about safety. So sometimes we have to do it. But that is where often the confusion comes in. Like even on the WebAssembly committee, were people start arguing, what does that imply? You should not think of this is a free pass. Just because we have to raise the abjection of something. Doesn't mean that we can't raise it to arbitrarily high. You should always do the minimal thing. If you can decompose something into simple things got you should do so. You should still stay faithful to that kind of overall, yes. So. And we can observe this becoming more and more interesting question over the evolution of the language. So the WebAssembly, we know every thing was pre simple really. This was intentionally designed to support low-level languages. So to get out of the door quick, those who were like our first line of customers, they were already on the web. So we wanted to accommodate them. And we intentionally thought of like, more like high-level language support for later. So that essentially is just the instruction, says what you find on actual hardware. And in the only knows machine types. That's all you have. Even pointers are just like --and the memory itself, you just have a flat array of raw bites, that you address and any linearity. So the one compromise you to do is there are bounce checks when you access the memory because of safety. Obviously this is usually implemented with just virtual memory techniques. And on top of that, you have a couple more notions like functions, tables and globals. And the modules which bundle the whole thing together. This is where it already gets somewhat more interesting. To let me take the functions as an example. So if you look at machine code. There is no such thing as a function. You just have code in your memory. You can jump to it, you can pass something and register all the stack. That is not the case here. Our code is organised into functions. And like a permit of ocean. So you define a function, defined as parameter types and arguments. And you have the explicit instructions for calling of them and the reason for that, there are multiple reasons but obvious ones are we don't want to expose the stack, right? And there is no way to get a handle on the stack it all. It is completely encapsulated. So that does away with a whole range of tech vectors that you have with native code. But there's also performance reason, that when you generate an WebAssembly code, you can't know what architecture you are running on. It might be registered to private architectures like X 86. Or original ones or ones that have tons of registers, how can you optimize that on the producer side right? This is something we have to lead to the engine where we have to raise the abstraction a little bit. And also the function tables, you can't get a function pointer directly. And again say a few reasons, safety reasons, don't want to expose physical code address. And what that implies is that we don't actually have a --we have a Harvard architecture. So code is complete least separate from data. That is the abstraction that we stick to. We could go higher, we could turn the foxes into closures. We could have methods or anything that could go crazy with it. But we don't. It is just code, it just code pointers and we stop at that. For the OCaml 2.0 we added a couple more things last year, and they're still fairly low levels of multiple return values. The big thing we added was vector instructions. But again super low-level exposing what hardware actually has. And there is a new type that is 128-bit vector. There is one thing that is a bit more high-level we start going into the direction of supporting the high-level stuff. Which is we now have new types of opaque references. Now you can pass around your first class manner a pointer to a function. But is completely opaque, you can't see it is a bit pattern. Which also means you can't store in memory and things like that. So that is a bit higher level of instruction if you want. The other instructions like Mam copy and friends, which we added again more for performance. Because every architecture has its particular tricks how you can make it that past. You can do it in the user space obviously and then you would not be as fast as you can do when you know your architecture.
                 And now we have been working on the whole time is WebAssembly 3.0 and there is some chance we will be able to shift that or at least create like a release candidate this year still. And has much more interesting features. So I will walk through some of them because they might be interesting to this audience. First of all, tail calls, finally we get tail calls [Laughter]!
                 Thank you. Yes this was a long ride. I think I wrote the proposal 7 years ago but just took ages for engines to implement it. And is simply just as two new instructions which are explicitly tail calls. So the idea here is again be explicit. There is no implicit optimization, TickAll optimization, the VM, the producer has to do the optimization and generate the right instructions. There is also exceptions. I might skip over that a bit faster. The kind of look like ML exceptions if you want. Except that, the catch clause, it has a jumper we will, if you have an except and you just jump somewhere. It is not like a whole structure thing. But other than that it is relatively high-level. To be more high-level than you would expect for similar language and again and things like typing safety. And also come position across manual boundaries and so on. And on the other hand, it is not, sorry. It is not super high-level because of the way it labels. Right, sorry.
                 And the other probably the biggest new feature, and the most controversial ones, that one by far is we are now adding build and support for garbage collection. So the first thing you should probably be thinking of at that point is why? I kind of do that myself. I have this little machine in my hands and yes you can and people have done it and people will continue doing it and is not a bad idea. Depending on your requirements. You may have to do it even in the future. But it comes at a cost. And the cost is the abstraction level that the WebAssembly operates on. So when you implement the garbage collector on top of the WebAssembly and user space. You run into some of these restrictions. You don't have access to the stack that you don't know what the registers are.
                 Us you have to maintain your shadow stack up things like that, all of this will come at a cost. Essentially, GC is like the worst case scenario for working on top of the objection like WebAssembly. Also pay for the balance check so what time and you know this can't fail but the VM, not only because of the user codes. So that is one big reason why we want to make this built-in. And then the others like for example exchanging reference with a host averment. So something for example, on the web is relevant people want to be able to pass reference to the dome objects through their WebAssembly code. So that has to be safe. And then there is the problem of when you have multiple runtimes that might run in the same WebAssembly process and multiple language is that have competing heaps and the performance problem's with competing heaps and competing GC's. Which you want to avoid. So we run garbage collection and still we want to stay true to the model of being low-level, right. We want to strip down to the bare basics. That means no complex types. It is just tuples and arrays. They really just describe memory layout. They tell the GC how to layout your data structures and that is it. They don't tell the GC what they mean. If you are compiling a high level language that whatever route code machine of type system the implements, you have to lower it to this very simple WebAssembly presentation types. Basically the same way that you to do with a native compiler. One additional thing we also provide is as a primitive is tech pointers in the form of unboxed scalars which are also a form of reference as compatible with the other. So this is a unique feature compared to the other VM's and again part of the story of enabling like the language runtimes to do all of these low-level things on top of WebAssembly. So very quickly what this boils down to if you have seen WebAssembly code, you get these new two forms of type conditions and you can form a reference to these. And on top of that you have this primitive I 31 reference which is the on boxing tact integer. So canonical instructions to do with them. And just the obvious stuff. I mean there are a couple more. But I'm not showing you here. It's kind of what you we should expect. Like if you know for example be OCaml's language and it looks similar except that this is typed.
                 And that is one of the challenges too, it is typed. We want to avoid any runtime checks when you access something. So all the types of reference, they are all really deeply typed. So if you reference something and the struck for every field it declares the tight. But obviously we can never be excessive enough to subsume innate all the source level type systems out there picks we need to have Netscape page that is cast. There is some form of caste built in here where you can work around the website. I built a whole like case study of the complete ML compiler, I will skip over that. I also built object oriented compiler with that to validate the design. So this was long and the making. It is now already implanted. I think in the major browsers. At least chrome and spider monkey. And edge. And already various compilers in different stages of development that target it. And the OCaml beckons there are also in the works are also going to target this. Also a bit more different for some other linkages like go or Haskell because they do more tricky things in their garbage collectors, among other things. So they might not be able to use that right now. Or maybe ever, it is not clear. But definitely a lot of room for improvement in the future. It is kind of like the first cut of our first support. So that is the WebAssembly 3.0 Wasm 3.0. There's a couple things I didn't mention. Like larger memory space and threading. This is coming now, the rest of the talk, I want to present to things that we are also working on that again are more interesting in terms of you know, advanced language features. So we are not done yet. There is still a lot to come. And one is the topic of continuations. So there is a big gap in the WebAssembly right now. It doesn't have any means of expressing control abstractions. The stack is not exposed. You cannot do build it yourself. Basically schools. So if you need to generate any of these got you really have to jump through hoops and you can't do it within WebAssembly itself. And of course when you, I mean this is a long, we have known this from the beginning, it was just it took us time to become a high enough priority with all the other things to work on it. When you talk to people on the WebAssembly. The committee or compiler, for folks what they would usually see is what we need here, is we need a way to do stack switching. Because all of these abstractions basically mean you have multiple stacks and you can switch between them. And to translate that to this audience. What they mean when they say is we want to continuation. [Laughter] that is kind of a more structured way of thinking about it. And I think I am also preaching to the choir here. When I say that, when people say that what they really mean is they want a limited continuation. Sorry, that was going too fast. I screwed up my joke. [Laughter].
                 So the fact handlers turned out the last ten years to be a particularly nice way to provide limited continuations. That is what you really mean or should mean. Or nodding of course. So that is a project we are working on now and have been working on for what is it? Two years or more, three years already? With a bunch of folks, some faces you might also recognise. Who were kind of experts in this field. So we want to add affect tenors in some form to WebAssembly. And here again challenges and they had to do with this being a low-level language. So one is it has to work without rubbish collection. Right, so even if you have the GC proposal that should always be the optional thing and not a dependency to use compiler these control obstructions. Also we don't have closures in them almost all the literature on the fact handlers-- and assumes that closures are total natural thing that you can just use. No. You don't have them here. Like you need to have a mechanism that allows you to work around. I mean you have recurring tail calls you know, tail recursion, and the loop constructs, we will be able to use that with the loop constructs, with the imperative control structure is the more natural choice on that level. And as I said earlier, you want a transparent cost model. So you don't want like stacks being allocated without you knowing when that has happened. Has to be very explicit. So these are a lot of constraints and they are kind of a fly in the face of what continuations and effect goes and looks like. I will just very quickly show you what the design that we have will look like. And basically building on top of the exception ending proposal that is already there. So kind of generalizing this notion of text that we have. Which wouldn't surprise you so the can now have results. And we have one suspend instruction which is essentially your perform. And the duel is resumed that takes the continuation. And is essentially applying it. And we have explicit insertion to create continuation from a function. All right. So this takes a function reference and creates a fresh continuation which when you invoke it, will call that function. Maybe ultimately return. The one thing missing here is or what happens when the actually invokes perfect. So what is bliss suspend go? Where are the handlers? In the handlers, oh yes, sorry-- one big you manage here is that continuation now or basically a representation of stacks.  They are kind of like a proxy to a stack on. And handlers are tied on to the resume injection. So every resume instructor has a table of facts and labels it and would jump to when effect occurs. And that label gets the arguments of that effect + a new continuation for resuming that same step. And that is all there is. I could see much more what that is very interesting topic and I think I have to hurry up a bit. What we also have a very interesting paper if you're interested. That you can read. And that is an official proposal, that we have a prototype of limitation of it as well and lesson time. And which is one of the major non web engines. And the lasting want to talk about is the components of WebAssembly. So the WebAssembly modules I mentioned in passing a couple of times. The WebAssembly as a module system, every binary comes as a module. The module is fully encapsulated. So X up for anything that you explicitly import and export, the content of a module cannot access. So it is a proper module system. And since it has imports, essentially WebAssembly model is now the first order and malfunction and function were. There is a close functor, there are no MBNA capability's and web cut you can't do anything lenses it it is given to you as an import. And the essential property to have sandboxing. So everything is a close function. So first order functor. So you can just pass in values. And to have API to instantiate modules or the CEPI. Sorry sometimes it is double react. There's no way to express linking. Also you cannot bundle modules and anyway. They are just this isolated things and all the glue has to be somewhere else. There is no standard way of expressing. So there will be many use cases for having the standard way of doing these things. And in particular, Luke who is like one of the fathers of WebAssembly. That is working at fastly now got so Vastly is this company that is betting heavily on WebAssembly. I think they are the largest content delivery networks and everything they do is in WebAssembly bit.  All the content they deploy is WebAssembly code. And in need of having more advanced methods of deploying but we got together and what is the model there and the software components. And I know this is kind of burned, kind of thing. That has been tried many times in the past. And often, more often than not failed anyway. But maybe this time with the right foundation, have a chance of getting it right. So another way of looking at is we want to define a language layer on top of WebAssembly in which you can describe modular structure. And you can specify the bundling of modules that you can actually import entire modules. And you can describe how they should be linked together with the lifecycles and all of these things picks you need to be able to talk about. And Luke designed all these things and came up with stuff and we talked and talked at some point I realise, you know what, you've just reinvented the higher order in a module system. [Laughter] and when we kind of polished and work out in detail that that is essentially what ended up being. It is a form of AML higher order. And it looks a bit more low-level. Because WebAssembly, but the essence of it is that the component is just a higher order functor an instance is a structure. And the linking is a functor to application. Is not surprising to them all people. But now that we can put in the mainstream. Can sneak into the mainstream. And there's also the notion of interface types. Which I won't really talk about but which will allow you to describe it signatures anyway that his leg which specific. And our ways of including ways of poorly which is implement Amy's components from work and lift their specific representations to this language agnostic interface language. And of course it comes with a form of select. [Laughter] okay. So this is also a proposal. At Stage 1 I think. Component level and Vastly is putting a lot of resources into building this with tooling and more on that and they want to release it this year, the first version of it. And also this is kind of the groundwork for making Wesi which is one big WebAssembly system interface. It is generic framework for defining portable WebAssembly modules that can model OS abstractions or something or can virtualize them. So pluggable in various ways. And basically the thing that you want to use to run WebAssembly outside of the web. Okay I think that is all I have. So the take away from this talk, just first of all, Wasm not WASM, is not an acronym. Not a web technology and it is low-level and language neutral formally specified and to an. And I hope I convince you that WebAssembly is technology that is worth considering for you both as a come PARylation target if you're language implement. Because it is running basically everywhere and there is more that we could have hinted at in this talk in all interesting questions we have to solve. And yes ICFP is already heavily involved in various ways here. So this is one thing that I could want to bring across. And this is because this is actually the whole WebAssembly process. It is an open standard. The committee just meets online. Everyone can participate, it is biweekly meetings, there are no prerequisites to showing up there. If you are interested, you can just or maybe not, maybe the first thing my tell you how to do that. But it is like, if this is something that would interest you, I encourage you to get involved, we need more smart people. More people with proper language background to listen and make this continue being the right thing. Doing the right thing. That is my talk. Thank you. 
>> Thank you Andreas Rossberg for this very inspiring talk. It's great to say this confluence of amazing yield ideas working well in the industrial standard. We have plenty of time for questions. 
>> Thank you Andreas, I'm curious getting that cast of characters involved from the beginning and yourself included. And the well understood of the tail calls, what were the tricky problems that meant it was long-delayed? 
                >> ANDREAS: I'm not sure I understood part of the first question. 
>>  I was saying given the cast of characters, that was involved, not as if a bunch of ignorant people designed it, and then you retrofitted it, till calls right? You were there and a lot of other very clever people were there. So there must have been something tricky about it. So I did show you the kind of process. 
                >> ANDREAS: I show you the kind of process, we have proposals. One of the requirements for something that it's standardized is implement it successfully into production engines. And that is usually the barrier were something crunches to and hold. And that has happened with tail cards in particular. And because the engine vendors essentially never prioritized it Heino. Their so much proposals going on and have so much work to do that they never really considered till calls is the most important thing right now. And also there was some things Microsoft but we can't talk over it. Adam? 
>> [Speaker away from microphone] 
                >> ANDREAS: That is a good question actually-- 
>> [Speaker away from microphone] 
                >> ANDREAS: He was asking essentially about what CPUs or other platforms, computational, processors that are not what this is modeled for, right? Which are pretty important nowadays for certain applications because they use them as coprocessors to solve certain problems. And this is a question that has come up. And some people asked like okay, target I don't know GPU with that? And obviously the design doesn't fit that all. So I don't have a good answer for that. That is not currently something that is our like target use case. You know. I don't know. I don't have a good answer. But it is a very fair question. But it is also something not usually, probably the use case where you care for the portability that much. Alan? 
>> So comparing Wasm to LL VM which is another player in the space. One of the biggest differences seems to be the LL VM has a model for undefined behaviour. And that is not a feature undefined. You could say some thing about that design decision? 
                >> ANDREAS: So the comparison with the LL VM. That is one of the questions we got in the beginning, it like why don't you just use LL VM? I should save some of the entasis of WebAssembly as it grew out of the SMG yes on one side and the whole pinnacle of fork effort at Google on the other side and pinnacle was using LL VM. Oh as their standard format. Because they were hoping that they could likely use a lot of the technology. Turned out it didn't work at all really. LL VM is not, it's terrible format for VM. Despite the name is not actually design for that at all. It's turned out it was completely under specified. And the back ends were much too slow for VM. And it was a moving target and they ended up doing most of the work that the LL VM could have done for them. And they did not meet much benefit for that. But the biggest thing for us really they wanted the well-defined semantics is that it has no undefined behaviour whatsoever. And that is not naturally something you will ever get even if you try to constrain. It is not just designed for that. I don't know if that answers your question. 
>> Neil? 
>> So in your talk you said Wasm already has exceptions and you're adding affect handlers to it. What is the story for their interaction? Does like it complicated? 
                >> ANDREAS: No, it's kind of similar as an OCaml, they are very closely related. So I mean you could always view exceptions with a special exception affect handlers. In reality you don't want to because the cost model is quite different. So within affect, need a new stack essentially, right? With an exception handler you don't want a new stack, that would be a cost you don't want to pay. So the whole, the very first design actually that we had for affect handlers, was really the exception ending proposal. And then we ended up having annotations for every exception construct saying can you resume or not resume? So basically we had already two different sets of constructs. And that was necessary to reflect the performance, the different performance behaviour. But other than that, if you have an effect declaration attack you can actually use it for both. Their in the same thing anyway. And you can throw exceptions out of the continue Asian and since they are structured, continuations, they do the clean thing, they should not be any surprise. All that we have modeled. They should be doing what you expect. 
>>  Okay thanks. 
>>  I had a question, SpecTech part of your talk was als interesting.  What is your story for migrating the large amount of documents you have now to this new thing? 
                >> ANDREAS: That is interesting because hopefully large amount of what is in there now you don't have to port because will get generated. So my vision is what we will end up with is we have steps of all the chapters ofSpecTech the and like slicing commands and which where you can run the generator over when it fills all the prose and the rules in that thing. And you really just have to keep the skeleton of things. I mean obviously there are parts of introductions at metalevel-- metalevel but kind of the bulk of it, I'm hoping you don't have to do much work. 
>> Language in Pullman taters have use the current spec to base their implantations on and moving to this new thing may introduce several discrepancies? 
                >> ANDREAS: No, I mean we have, so the current is supposed to change at all, that's a total no-go. We also have to try to basically keep that one reason why our own tools so that we can build it essentially used the exact same formation. That we already have. In the spec we don't have the major changes to that. And the structure of how that link just specified when we move over. So is just a way to generate  laborious way. That is less. 
>>  I have a question, I was a bit surprised when you said that we have all these different semantics, limitations in different languages. And you said let's create another language, as a solution to this. I would have thought if you, I was just interested about your thoughts there, a visit better perhaps to have multiple implementations in some way to see whether or not they are consistent? As a means of trusting versus having the single source Of truth? 
                >> ANDREAS: Yes I could see that being an advantage. And practise though since WebAssembly is so semantically many ways fairly simple. I don't remember us ever having discovered serious discrepancies between the different implementations. And we have a pretty exhaustive test suite as well. So even between different engines. And I view that is Axley part of the success story of this full formalization ever. There has never been a discrepancy between the WebAssembly implantations in the wild. Except for straight up boxes somewhere were some thing actually crash. That they behave differently? I don't remember a single case for that happened. I could measure for more complicated semantics, that might be more relevant thing. But here, at least so far, it did not really turn out to be an advantage. 
>>  One last question. 
>> So you spoke a number of times about keeping things as low-level as possible. And one of the things that I have for a question, if you want to have two differently which is there both compiling to us and then they call into each other, then obviously they need to know, you know garbage collection is one step towards okay now they don't need to know about how they allocate memory. But they do still need to know how our values are represented, if you want to represent objects, if you have two objects and then call methods on each other, is has to be some agreement. Is this something that people have considered? Is there some work towards this end? 
                >> ANDREAS: So the multilanguage interrupt was very conscious not to design goal of WebAssembly. Because as far as I'm concerned that has never worked in practise. It is kind of like there have been projects, like major projects in the VM s that claim that is their goal. And in reality there is always like even little language impedance in this measures already make the whole thing fall apart. So we very explicitly to make that a non-goal of WebAssembly. Which does not keep anybody from if they want their linkages to interact. What you have to do is you have to agree on ABI essentially. Like we do in native land, and people could do that and they could write a standard ABI and stick to that. That is one part of the answer. The other part of the answer is the component model that also tries to address that question. And some more higher-level. What you have to address these language, high-level language neutral interface types. That can express data structures in a bit more high-level. I did show what they look like. But they are very canonical kind of algebraic types if you want. And then multiple languages could speak to each other through those. And that is a relatively high level model. It does have no shared state whatsoever. So if you need something in between, there is nothing right now they can just pull out of a shelf. And use. But there's also nothing keeping you from defining such a thing. 
                >> NIKHIL: Thank you Andreas Rossberg.
                We have a half-hour break before the next session, slightly less, 20 minutes, sorry.
