                >> MATTHEW FLATT: All right good morning everyone welcome to the third day of the ICFP programme. Very happy to introduce our keynote speaker this morning, Christine Rizkallah. She is a senior lecturer at the University of Melbourne, PhD is from Max blanket from 2015. And she taught at Yipta and UPENN. And her work is on making practical and easier to apply specific domains especially through specific domain languages. Areas like algorithms and security and social choice theory. Which I have not read the paper yet to find out what that means. But today I think we will be hearing about system software. And applying tools to that. So let's welcome Christine! 
                >> CHRISTINE RIZKALLAH: Okay thank you Matthew for the introduction. Yes today I will talking to you about two projects we have had running since 2013 I think. The cogent project and the --project. Before we go there, me make sure I'm playing this correctly. What is my motivation of this work? So some software motivation in general you want to verify your software that make sure it's correct but not enough to verify applications like algorithmic library users, crypto protocols and whatnot. It's also important to verify the underlying systems. Software. So the underlying microkernel but other things like filesystems, device drivers and networks tax.
                 Because if you only verify your file system applications you could have a bug in your file system and it could have an attacker and  have a bug and undo the guarantees that you already have. So where did the verification stand a while ago? I think that a lot of, there is a lot of good work in the interactive they are improving. Two projects that want to highlight are the concerts seL4, and I think both of these project stands out in some way. And in my opinion the reason is they did not compromise on the trustworthiness or on efficiency. So the concert is and optimizing C compiler. Generates efficient code and it verified coq in seL4 and is verified in Isabel/HOL and they did not scale down and it took very responsive PhD students to verify them seL4 and took about 25-person-years for about 10,000 lines of C code. If we want to scale up we need to do something a bit differently.
                 So think the problem is that verifying systems like always starting from see by bit force is extreme the costly. So the aim of this work is to reduce the cost of verifying software. And without compromising on the efficiency of the software that is being verified. Or and without expanding the trusted computing base that we have. So without adding more and more tools. And not having the specifically languages that work with a potato type of software. But just at least the linkages that are restricted. And sufficient for verifying software in a certain domain. And in the past we have looked at verifying filesystems, currently we are looking at verifying device drivers and then we went to look at the network protocols. And in order to reduce the effort and verifying software. We want to automatically abstract. Both the code, so maybe when you are, when you're systems folks or algorithms folks want to implement code. They typically want to implement in the low-level language. Is not because they like pain and suffering, it just because they want to have efficient code I think.
                 When we want to pair of high code, typically you prefer to have mathematical functions because they are easier to think about proving things you don't have to worry about pointers and memory and guards and all of that. This is regard to code. And then in regard to data, when you have very low-level system sometimes they want to have a handle on how data structures are implemented in memory. So they would deal with things like bit fields or just specify a bit by bit where things are laid out. So that they can operate on this data efficiently. And it is hard to get the code right when you're thinking about an array of bits of memory and bites and whatnot. So I think both in terms of implementing and verification it would be preferable to thing about algebraic datatypes if you get away without compromising efficiency. Yes so the two projects I will talk about, one of them is cogent and it focuses on the automatic refinement of code. So basically how do we reconcile these two views automatically? In the other code is called tangent and has to go with reconciling these two views. We want to use functional languages because these increase the productivity in terms of the verification and I think in terms of the implication you can write less lines of code. And also want to have type systems that can automatically force safety and security properties. And why the type systems, because programmers are the comfortable what type systems. If it can automatically enforce properties that they want to have and maybe even provide a proof that this property holds. Them this is a very lightweight way of getting from the method somehow. And certain compilers, verified compilers are the reason why we have these automate large portion of verification. Basically by abstracting on low-level code into functions then we can prove things mainly in top of that. And so why worry interested in the filesystems this to remain an open problem for a long time and it was posed as a grand challenge back into thousand 8. And various groups worked on this problem. And I think the reason this problem is quite difficult is because there are many filesystems. For example Lennox has about 50 of them and each of them has about 5,000 lines of code. So I don't know for 10,000 lines of code that took 25 years, you do the math.
                 One thing about filesystems is also they are very boring. So a lot of the code is extremely tedious. Which, boring is good and it means we can automate things. We can have a small language and it can cover a lot of that code. And in order to verifying filesystems, what we decided to do and by we I'm telling you who we are on the next five. We created in which called cogent. It is a restricted language and I will tell you what that means. It is not sharing complete. You can't moment everything in cogent.
                 It is functional and it has a linear type system. And certifying compiler. And the certifying compiler generates codes and proofs and I will show you a picture of what this looks like in a minute. But yes this project has been going on since 2013 and many people over the years contributed to this project. And Liam heavily debated to the language design and DD as well as the contribution and Gabby contribute to starting up, starting the project and then more recently Vincent and Lewis have contributed to this project. And many other have made various contributions.
                 Some of these fallen the systems domain, some of them fall in the row, linkages, others fallen the verification. And we are all working together in sync back and forth. In designing this language. And I think that, that was quite important to help with the design I will tell you what the results were and I will get a bit more into the detail of how we went through it. And so yes, it is a functional link was with the certifying compiler and the linear type system. I will tell you what that also means any moment. But basically implement it to filesystems in that language, one existing file system. And then one that we design from scratch. It is a journaling filesystem that is quite complicated. So Sydney Imani is on this for his PHD project. And we verified the functional correctness of two key build B file system operations. And in this verification we have relied on automating large part of this verification. Because we implemented them in cogent and then use the certifying compiler to prove that it is similar to the C code and then like verified the file system operations on top of the functional semantics of the cogent code. BilbyFs was first implemented and see and then in cogent. And then compared and convince ourselves that the, we are generating is cogent and inefficient and has similar performance to the handwritten C code.
                 So in case you want to refer to this work, we have a more recent paper that subsumes other papers. And this is the language one. And then this the systems work, is still from 2016. Write up.
                 What is the linear type system and why do we want it? The linear type system is really simple. The variables I have a linear type must be used exactly once. Okay and why do we want that for many reasons. So when we have a linear type system that allows us to generate efficient imperative code. Because and I will show you any moment why but basically the idea is because we don't need garbage collection although we have a language if we know that everything is use exec we once you can replace by something else. And allocating a bunch of memory at the beginning. We use it and free the variant. And it helps with memory management because it gives us a functional view of the language and the imperative you of the functional and imperative semantics of the language that happened to coincide. And that means that nothing that has to do with pointers or memory can never go wrong.
                 So the way, if you implement code that has ensured that all your pointers have a linear type. You get automatically that you don't have any memory errors. Okay?
                 Most importantly for me is that it gives us a really nice high order logic. Representation of the code that is easy to reason about. Because we don't have to think about memory at all. So you don't have like this status threaded through anyway. So you can think of everything is in a function. Of the functional semantics for the cogent and you have functional semantics for the cogent and semantics for the functional semantics and the higher order language that you get. Okay so what does the cogently which look like? More or less, I'm not going to go introducing the full syntax. But it has the typical types, because of the linear types if you want to use everything exactly once you need to use every field in the record exactly once. You kind of need to be careful and tracking what have you taken and when did you put something back so that you can take it again so that you don't access any of the fields more than once. Right? We have these take and put operations also.
                 And now cogent doesn't have recursion or induration built in. Instead, it has foreign function interface to template see. We have a library of data structures that are implemented in C with and planters over these data structures that we can access back-and-forth. And I will tell you how this plays into our verification sorry. Just a bit later in the talk. And the loops are implemented as iterators over ADTs. Which systems folks tend to like because even if we offer them recursive types they will not use it. And so we have words of various sizes, we have like one bit words as well. We have records, and various abstract types, function types, and I will give you a couple examples to show you how the linear types are working. So the linear types are used exactly once an access use twice. This doesn't work. Letter X is you 0 times, this doesn't work. Okay X is used in the then condition but not the else condition doesn't work. So you have this style of vetting things as well. So X is equal to some data and you can update X and say it in a new variable letter Y and then give letter Y back and so each of X and letter Y is using likely once. So now looking at this you can see the C code that generated from that. And the C code will use the same memory occasion to store the X and Y.
                 Okay so the linear types it sounds a bit painful to have that. And why we get away with all these restrictions on the types and also with the ADT's and whatnot. And so on the idea of the project is we want to write as much code and cogent as possible and that will simple fights verification. And then we want to write a small portion of the code in C and verify that code manually, compose it for the cogent so the composition uses it automatically using the framework. And reuse the small parts over and over. Okay so these small parts are for example arrays or trees or data structures that are used across various systems then we could just reuse them. And amortize the effort of verifying them over all these various systems. Okay so here's a picture of how this looks like.
                 We have a cogent programmes and let's say it's entire file system. Bassett to a certifying compiler and a certifying compiler gives you out three things. So it gives you out efficient C code. It gives you order logic functional specification of the corporate but this is not the specification you want at the end write this is mirroring the cogent code and you still want to maybe prove additional things on top of it manually.
                 But it's idea for the case reasoning about the cogent code or about the system in general. And most importantly, we don't just get like memory safety out of our certifying compiler we get further refinement proof. Mainly we get a proof in a theatre improver that says anyway the higher order logic can behave and at least as many ways as the C can behave or more or less they can do the same thing. And that means that anything that we prove about higher order logic, we compose that theorem with our compiler, generated the room. And know that it also holds for the underlying C code. Okay. So yes I think this is really the main idea. And this proof is really like actually a sequence of many, many smaller proofs. With languages inside. With various embedding's of cogent and whatnot. But yes, this is the basic idea. And we also get a proof that the programme is well types for example like generated. Okay, it's not only that. So I said that for cogent has a foreign function interface to see. So actually yes, that the code can be passed to the cogent compiler as well. Let's say for example CADT or CAT, the and the cogent compiler will link the two and give you a bunch of us options about the C code that you may or may not want to discharge in order to get the final theorem about the entire system. So the peer function spec of the top is a functional specification of the cogent along with the C code. So you pass the C code you pass the specification of the C code order higher logic and you have to do manual. And you also have to prove the C corresponds with the functional specification you proved. Also have to prove an additional theorem saying that there is not mess with code on. So we been like a tracking memory got a memory very carefully, you can't just go into the C part of the programme and also respect its functional stack. And then cogent gives the compose verification for the entire system for free in a way. Okay. And yes recently we have finally verified our array library per se, our word library that showed on this example is the same ones that was used on the filesystems.
                 Okay so what are the results of this project? So we were able to implement efficient cogent consistence filesystems and I mean there is some narrow cases where it's less efficient than handwritten  code. But overall performs within maybe like 10% difference to be by a standards quite efficient. So implanted two filesystems. In these filesystems each of them was about 4,000 lines of cogent. And in addition of the 2000 lines of C code. So for the cogent parts, cogent pneumatically reduce the cost of information. It was about one third, for seL4 the it took about 1.65 persons months and for the filesystems about .38 % months per 100 cogent and is a bit surprising because we think that the functional code makes things a little bit smaller. But I guess we have a pretty sparse notation for the cogent at the moment and you have all of these linearity's you to keep passing things around. So is about 1:1 to C but that still saves us like two thirds of the effort for about two thirds of the filesystems. And this is to be taken with a grain of salt. Because one of these is about verifying operating systems and the others about verifying filesystems and I already mentioned that the filesystems are kind of boring. So maybe they were easier, I don't know. But yes like two thirds is a big deal. So even if you say it was half the effort, that is still worth investing in.
                 Okay, I did say a small part in C and now I'm saying one third of it is in C so what is that about? How do we deal with that now?
                 The follow-up tangent project, part of it is about reducing these 2000 lines of C code. And the other part is about also being able to verify more code like the device drivers which would be completely impossible without data representations and whatnot.
                 So yes, like some of this is reusable. Some of this like ADT libraries. And these are fine because we verify them once and we use the many times. It is okay. For other parts, other parts that were the most painful and I will show you that any couple of slides. But that is basically the type mismatching between the layouts that cogent takes because the cogent compiler is just the compiler, right? See you give it the cogent type it will generate the C-type in a very standard way. Records converts to struct. And the letter C that you get is not exactly the C that the system folks want. Or you have surrounding systems expect. So you have the file system it lives among other pieces of system codes. Is not the layouts that they expect. So you have this layout mismatch which means that we have to serialize and deserialize information back and forth. And is horrible. It is error-prone. It is really boring code got we don't want to verify it by hand.
                 So yes so this is the type dispatch problem.
                 And yes, and another reason is like sometimes systems it folks just want to use the bit fields or want to have strange tapping and alignment. None of these can be expressed by a native cogent type. So they have to implement everything that they want. On these types in the C.
                 So our old solution was to define, yeah, and abstract type and cogent that a logically equivalent type. So abstract type in cogent implement it in the C and have these marshaling and marshaling on operations back and forth. They are error-prone, inefficient got you to do copying and whatnot and they are very hard to verify. So can we do better?
                 So let's start the other half of the talk. We can shift towards more cogent and let's see we can also probably improve our verification interface between cogent and C.
                 So I keep mentioning this interface between cogent and C. So yes like cogent programmes are part of a larger system. For example even if it is entire file system, it is going to run and be surrounded by other systems code. And the connected, connected to these outer systems, to foreign function interface. FFI. Most of what was implanted in letter C at the point was ADT's and also this matching up of layouts. So I will focus on the matching up of layouts. We have a few ways to get around this or like the choices there, right? We can only use the cogent types but then we won't have any C integration so that is not an option. Can only use the abstract types in the C. We will not have to do any conversion or anything but then we don't do for from cogent at all.
                 And we could do conversion by copy so that would not be efficient. We would have a lot of boilerplate to actually do the copying. But we would be able to integrate with C.
                 The last option that makes verification people shiver a little is we could just do conversion by cast. Right? We could just say take this, pretend it is something else, I'm done here. That can go wrong.
                 The conversion by cost is not bad per se it's only bad if you actually don't know how things are laid out. So you can imagine have it in you language that you can specify how things are laid out and you got some mom guarantee that you have them laid out as specified. Then you have a cast, and the first. Contain something as the fourth contain something else. You can view them as whatever type you want as long as you know what the type contains. So as long as you can ensure, like cost with more information. Do it properly. That is basically what we did. With the Dargent language. You see that there is some overlap with the people. All of us have different affiliations, there is not a single affiliation, oh no that is not true. Vincent and I have the same affiliation now. Everyone else has different, I'm not on the slide so everyone on this slide has different affiliations. Yes [Laughter].
                 So Zilian was the main person design the Dargent language for his PhD. Ambroise was a very heavy intruder to the extension of the certifying compiler framework for this. Liam and Gabby helped work with the initial designs of the linkage. Craig helped with the source of the compiler issues and Vincent was everyone's adviser on how to do Isabel well and after two years of using Isabel somehow.
                 So Dargent, what is Dargent? It is a data layout specification language with verify data refinement from algebraic types to their memory layouts. And you are allowed to take these memory layouts, down to the bit level. So basically use the programmer, to sit down, and write your algebraic types. Define how they are laid out, declaratively. And then have the compiler take care of generating access functions, to access these datatypes. From the memory the bit array that is below and it is giving you a guarantee that it is setting and getting things to the right places. Okay then you can do everything on your algebraic data types, implementation wise and verification wise and not worry about these data bit level representation of your programme.
                So how does this exactly look like? So you see the example but basically you have the cogent type before, sorry the cogent programme before and you passed it to the compiler. You can have your cogent programme again, using the same types, pass it to the compiler, but now you are also passing this data layout specification for each type. Or for each type that you want to specify the layout for. And then what you are getting out is again just like C code now lower level C code. So C code that instead of using structs and things like that you have bits and array, bits and memory and your managing it. But yes and then this I don't know, run on underlying devices that expect that specific layout for example.
                 So more concretely here is an example, so we had the cogent code here is a word that has size 32. You can access that field in the record by in the usual way. So you would r.a =4 write and the C code that we generated for that was what you would expect. So just the struct with an int be and then you would sit and get the feel this way. So this is an algebraic view of the data structure.
                 With Dargent, now the sequence we are generating is lower level pics we are generating array bits of memory. And we are generating two functions. Two functions for every field of every record for example. So a getter and a cider. And again the getter, you still have the algebraic view that you could just call the function get and call the function set and not worry about where it is getting and setting into the array.
                 But under the hood, what these getters and setters are doing is that they are getting and setting from the right place and the huge array bits that is created according to the specification that you are providing. And these are generated by the compiler. So they generated by the compiler as specified by the layout that is provided by the programmer. And they allow the programmer to code using algebraic types. Okay.
                 Here is an example with some colour in it, I don't know about the font but at least has some colour. So you have a record and it contains three things, it contains another record, a pointer in the variant. And now you could write that this, yes so it has the record pointer and variant. And now you can define that the layout of this record is as follows. It has a record layout, a pointer layout, and a variant.
                 And here for each field in that record you could give a size and bits and bytes. So B is bytes and small b is bits. She could say for example X takes 4 bytes and b takes one bit. Yet I don't know something like 8 bits are the character and something that now we can represent them using one bit. And similar for the variant you can just say the tag of the variant takes one bit. And the second alternative takes 2 bytes so then you can reuse the same memory for the values of the tag. And so here you can define and offset. So for the pointer, we first put letter X and then we put Y and then we put the pointer at offset 8 bytes. So defined by the user I went to byte  the number eight and up at the pointer their. And you can find that the very is starting at byte 5. Wi-Fi the not for? Because I did find it that way. I could define it however I wanted. So I put five, I put the variant, but the tag to it's one bit. And if it's bits 0 then you layout the other X here and if it's one then you layout the Y here. Yeah dipping in the value of the tag. There's some syntactic sugar on top of that but make it less verbose but you can define every thing down to the bit level. If you want to.
                 How does this look like in terms of the compiler certificate that we are getting? The certificate is the same. However, we are getting it for lower levels C in a way. Like the C code now instead of using structs and whatnot we are using bits and rights and memory. And it could operate on these getters and setters that are generated by the compiler. So the compiler is generating this on the key level and the C code uses these instead of the struct the operations we were using before. Yes, we are also generating some additional theorems just for sanity checking. And also because we want them. And I always think about the higher order logic programme and I don't care about where these are laid out. This is not. Actually surprising how fast we could fix the compiler, fix the up, update the compiler to account for target. Because the only phases that we had to change were the lowest phase like going from the imperative semantics down to C. And also the typing proofs. Does anyone have any questions? 
>> AUDIENCE: I miss how you define the struck definition and correspondence with the layout specification. 
                >> CHRISTINE RIZKALLAH: Yes that is the other bit that we had to change, I was waiting for that exact lesson, thank you Nik, [Laughter].
                 The other thing that we have to changes well typeness the proofs. One thing that we want to check now we are checking the well typeness is also checking the layout matches the type. For example five say that this is a word of size 32, the has to be four bytes. And I need to get an error from the compiler saying that there's a layout mismatch and I do get an error from the compiler. And if the compiler excepts the programme and the layout matches the type and we are generating proofs that the type and the layout matches. If they are excepted by the compiler. So we've accepted also the well typeness, I should not say well typeness gives we were very careful to keep them separate, we don't want to complicate the type system anymore than it needs to be. So it has the well typeness checks and then the layouts match okay. And this additional theorem that we are getting is telling us that the getters and setters are owing to the right places that are defined by the programmer. So when I'm proving something about the system like properties about my cogent programme. I will not need to talk about these layouts at all. I just need to talk about the higher order logic and specifications which look exactly the same as the ones we had before.
                 But what I want to link this to other surrounding systems. And I want to do my cost, right? I will need to know that these, getters and setters are getting and setting so I could want to cost them as something else to know what corresponds to what. So I could use these additional theorems them. Any other questions before keep going? 
>> AUDIENCE: How do you know that the layout that you are verifying matches the layout of the C compilers going to use? 
                >> CHRISTINE RIZKALLAH: The C compiler will not use a layout. Because if we are generating, okay if you mean from the surrounding systems or just from the system? So here we are generating an array of bits of memory. So the C compiler will not be doing anything at all. Right? There are no structs no or anything unions or anything and letter C that the compiler will decide and. For surrounding systems if the surrounding systems you use the array of bits of memory, then the C compiler continues to not to have to do anything. If they decide to use structs and the compiler will lay things out. Because there scrolls I don't know how they know but they seem to know. Assume that many. They can either assume that axiomatical it or just force the compiler to not do anything and specify their bit fields or arrays of bits and memory again. So yes that is one thing we would do. I would prefer if people did not rely on the compiler anything.
                 And one thing and would love to have in the future is Dargent for C. Allowing the systems programmers to write structs write as specified by the programmers I think that would be also nicer and they can use the algebraic types and they don't have to assume anything and they can specify on the C side how they can be laid out. But that is not something that exists at the moment.
                >> AUDIENCE:   So been-- from all types. One thing especially working with the hardware and currently in concurrent systems. We are exchanging sort of bitwise data around. It is not essentially the eventual state memory that matters but also the order in which you perform individual the order of the operations occurring. Within particular structure. I hadn't algebraic representation of my conceptual data. I actually need to take care to mutate things any particular order to make sure that the harbor does what I expected to do or another thread running on my machine sees things in the right order. And yet this sort of degree of detail is differently abstracted out in the ADT. In your conceptual types I guess. 
                >> CHRISTINE RIZKALLAH: Yes.
                >> AUDIENCE:   So is that something you cannot rely on Dargent and more abstract representation for in these settings? Or is that something you thought about? 
                >> CHRISTINE RIZKALLAH: I mean we did is we introduce the one bit type of Dargent and that low-level details and then you will not use algebraic type for that one thing. If you need it up to the bit level you will define that it is up to that level. You know it's one bit or something like that. But you are asking what if I want to know something about the layout at the top level? Is that your question?
                >> AUDIENCE:   The question is more about ordering, so if I have a some instance, we can take this off-line actually is probably more detailed. 
                >> CHRISTINE RIZKALLAH: Yes okay I'm not sure, let's take it off-line because I'm not sure what the question is. Umm. Yes okay.
                 So yes what are the result of this project in a nutshell? So we have the language that has the data specification language and it also supports polymorphic layouts endianness and annotations. And certifying compiler generates getters and setters layout these types as specified and also they continue to produce this Isabel/HOL proof that C the code responds and also that they respect the Dargent layouts. The implementation and manual very vacation still operates on the algebraic types. And we use the timer driver and power control system using the Dargent. And they also verified an LED but we haven't published that you. Would like to verify more drivers using Dargent, because we are quite small. Like the programming language and verification folks and wanted these, it would be nice to have some people who are interested in systems could like help us understand more diverse. It was really easy to do for the verification. I mean these are small. But the C code was horrible bits of things and stuff like this. As soon as we understood what the C code was up to and understood this fact. It was really easy to write the cogent code that was just a few lines of code. Because now we just lay it out, it's like get it there, done. So a lot of these drivers is just like take this thing, put them together and put them together like this and put them out. It's all getters and setters the combining and all of the hard goes away. So the verification was also trivial.
                 The biggest of these which was quite small talk about one week to verify. Once we had the implementation and spec. And so for more information about Dargent check out our paper from earlier this year. What is next? The actions that we took and are taking, a horizontal position of cogent and C.
                 So I said that we can compose proofs of cogent and C. But we have had the frame work for a while, we haven't actually tried it out. So now we tried out, we verified the C and A implementation and verify the combined system through the cogent FFI and it works. The person who didn't like say. I don't like it. [Laughter] so I think one thing about the C code is you provide the letter C and you provide the specifications and you have to kind of proof that it is in sync at every level of quotient, and there is many levels of proofs and you kind of have to mirror these on the C side manually. The person who did it primarily that liked it was Lewis because it said it guided his thinking. One level was like getting rid of like memory like abstracting away memory. One level was like abstracting away doing, going away from memory free to blah, I think there's a lot of room for automation there. I think there's a lot of repetition. Automating the parts of these. Or even better, what we are looking at is how to allow people to prove stuff about the C code say using separation logic and composing these proofs with cogent proofs. Like with the notions of separation from linear types of separation logic. Should coincide, don't look quite visually the same for us. We have a property based testing framework for cogent.
                 And that is because we want to keep updating the language, the verification will not always keep up with the language development. So we want to do some testing before we do, before we start verifying additional features. And also because we want to verify it like above the, so the automatic verification is up to the higher order logic level. And we want to go, we can go some steps higher if we do testing, right Mike we can just test high-level properties on top of that. Or test of the C code, the combine system without verifying the C bits annually before verifying the C bits mainly and then Professor Gunnar Teege in Munich developed Gencot, a toll on my click converging C to cogent and then back to letter C and I get the higher order logic specific about the C that is generated get the higher order logic for certification about the letter C that generated improve stuff on top of that. Their using it verifying was it? I forgot some codes. Don't know something to do with keyboards. Maybe it was the driver as well. And yes it is quite exciting but other people are actually developing stuff and using this.
                 One thing that we are doing is adding primitive recursion to cogent although it is not the top rarity for the systems programmers, I don't think it is that difficult and is kind of a function of the language that should have primitive recursion. What is a little bit more difficult and not about or something that we had to do was simple met the termination checker to ensure totality, because we want to make sure that the higher order functions that we are getting are still nice and reasonable and if you are improving like Isabel the cogent functions should terminate. And we got carried away there a bit in a good way. So we left cogent for a bit started working on the termination checker's and lambda. We want to verify more datatypes and drivers using cogent.
                 And yes we are also adding a limited form of our race and that is not too difficult. Fixed size arrays, nonlinearity and arrays together. Just arrays of unboxed things. If you want to do a linearity and arrays together. Things get way more difficult we need to add support for refinement types. We have several tiny prototypes of that-that are very far from finished.
                 I want to improve the verification interface. So the horizontal composition between cogent and C. We look at the bit like language based security, information flow, linear types and are nice and contract things. There is the max system, I don't know like access control-- Marco, Sina, Alejandro, Russo and others. Use the monads in Haskell to track information flow control. Some relationship between monads and would linear types. Started looking at how to extend the language to support the project for the next five years or something. Also looking at the currency.  Looking at the languages and leaving the codons and go back to simpler languages. That is it, if you want to do something with cogent and Dargent, they are public. They are on GitHub. Please do. We have had a lot of support with the Dargent project. And this case the support for the Dargent project, I have changed institutions and these projects are now finished. So if you want to support this project, please do [ LAUGHTER ] if you have people who just like new leg which is an want to try them out, please do, [Laughter] we are happy to get feedback about the language and continue to improve it. Thank you everyone for listening. 
                >> MATTHEW FLATT: Okay I see that people are lining up for questions, that is great, remember to state your name for the benefit of everyone but especially the online audience.
                >> AUDIENCE:   Hello Adam Chapa from MIT period I have two questions about the recursion feature that your adding. It sounded like simultaneously you're working harder than I would expect to put that feature in their. But also missing an element that seems important.
                 For the first part you said your adding primitive recursion only but still you have to prove termination, that is surprising. And for the second aspect of that, you didn't mention proving status base usage bounds which seems really them for different systems code. The kind of generalizes termination. So how do I make sense of both of those together? 
                >> CHRISTINE RIZKALLAH: Okay I said primitive recursion, I lied. [Laughter] we started with primitive recursion and we are creating so we wanted to extend that to bigger classes of functions that terminate. And that is what got us off track with the more interesting on track, off-track and on some track with more interesting termination checker's. What else?
                >> AUDIENCE:   Stack balance. 
                >> CHRISTINE RIZKALLAH: Stack balance, you are saying that is a pertinent we should look at how to like bound the stackers?
                >> AUDIENCE:   In a note you would generally assume that you stack will resize dynamically and if you are out of space. Okay future work. [Laughter]. 
                >> CHRISTINE RIZKALLAH: Yes. I don't know if any of these recursive type features will be used by system type folks. I think I need to talk to more people in the PL community who have been in the, PL many for longer to understand how recursive datatypes have flattened into arrays and optimize and whatnot and them understand what is possible and whatnot, and that was my kind of intuition of what needs to happen but I don't know when I can flatten the recursive structure into summary. And what is a reasonable amount of memory and what to do once that runs out. I'm sure that there's a lot of things that compilers do out there. Happy to learn from a and happy for people to refer me to material to learn from it. Because I really don't know how that is handle. But yes. They were two questions were?
                >> AUDIENCE:   Hello-- thank you for the talk. One big part of the project was to basically raise a little bit the level that you have in the embedded code when one big part of the project was to raise a bit of the level code and that they have in the embedded code and to try to make them use algebraic code that they have. How does that work? 
                >> CHRISTINE RIZKALLAH: Use this like on the embedded systems.
                >> AUDIENCE:   All drivers, all drivers and all these kind of things in general. 
                >> CHRISTINE RIZKALLAH: Unfortunate we verify just to drivers, and mostly PL, and verification folks did that because we do not have too many systems folks around at the moment. And what we have the system folks around and we presented this language, request were --and other one that I'm still working on is going to take a while which is dynamic size arrays. Which objects inside like takes. It was like, it was not that people wanted to implement its Mbytes of memory. They were happy to abstract away from that. It is that they want very specific code and very specific data structures come out of the other end. And if we could provide that then they would be happy to use it. That was my impression. System folks because they are SCO for folks and they are happy to bend over backwards together verification working. So now, I think in this particular instance actually it was exciting for system folks. Because one thing is they do need to do the marshaling and on marshaling serialization and serialization anyway if they use that sort of all direct types of the C side. And just having that go away meant that they get more efficient systems and people are happy with that. 
                >> MATTHEW FLATT: Let me try to relay question from online. About layout. Are the layout specification sufficient for the ensuring atomic reads, as you can -- I will try to generalize this little bit, when you're dealing with device drivers, there's often some inherent turned her and see and you have to worry about half rights or something like that. Does that show up at all? 
                >> CHRISTINE RIZKALLAH: It did not show up for us, what they show up is another thing that we are looking at is when you have sometimes you have these what they are called volatile registers and so you don't know what you get out of them. And there is a way to handle it through the current cogent infrastructure by just abstracting over that. Saying that I get some value from this. I get abstract over what the value is. And just basically how random numbers are generated, you have the random generator getting the letter sees and then you see is a deterministic and then you obstruct over the seeds and to see the random number. So I've done something similar here and just like pass the additional seed parameter. And then abstracted away at the other end. And you can just have one layer of abstraction on top of the higher logic code that you get where you abstract away the seed but you have to know what the seed is to extract in a. We don't know -- we don't do that automatically. I just it automatically manually to try if it works. And if you abstract it away, then you can pretend that the value is nondeterministic and that works, I think there are other ways to prove this, improve this but basically allowing the specific to foreign functions for example to be on deterministic. But it works. It is annoying but it works.
                >> AUDIENCE:   Thank you.
                >> AUDIENCE:   Hello I am Pakuna Aming from-- I wanted to ask you do you have any excitations or impressions on how much caution and partial approach could reduce the verification of concert or sell if they were to be done again? To certify for the construct?  
                >> CHRISTINE RIZKALLAH: I can imagine having something like Dargent for C and then having some they like the concert compiler ensuring some certificate about layout. SeL4 I think operating system typically share and do a lot of sharing, inclusion is good for components that don't involve much sharing. And when you have a system that involves a lot of sharing, you won't get as much mileage out of the language I think. I'm not sure if that is what you mean? Like re-implementing.
                >> AUDIENCE:   And operating the system? It is to project I proposed -- that were proposed as the examples of very expensive verification. I see well maybe now that we have approaches like-- 
                >> CHRISTINE RIZKALLAH: I see what you are saying it I think it was more proposed as a motivation for why it's important to them and like for the cogent and particular, and the device drivers and the sort of systems that don't have a lot of sharing. That's why the linear types where the right answer for this domain. Maybe some other language would be good for abstracting and operating systems. Cogent relies on a tool called auto chorus the abstracts deep embedding of C so C semantics into monads. Like a shallower come on attic C or a monadic representation in Isabel/HOL and the for fusion was done I think using auto cores and I believe that at least some large portions of it was shown to be good for that. I think there more obstructions good, you just need the right type of abstraction and I don't think cogent the right type of abstraction for the implementing and operating system. Darwin could be a good idea for other languages. --Dargent.
                >> AUDIENCE:   Could be a good idea for other languages. Hi, thanks for the talk. I think it seems a number of projects in the former verification space rely on the formal semantics of the C, right? And I thank you just imply that you are sharing the same semantics between seL4 the and your project. Presumably has a different one. Is there any reuse between the specifications or are you know that they are correct? Do you know that it's semantic models is consistence with Coq? 
                >> CHRISTINE RIZKALLAH: None of them are consistent with another. I think the semantic because of letter C is under specified and each of them specifies the bits that are under specified differently. I don't think if we are using any parts of that, I haven't. I haven't thoroughly looked into it. Talking about Coq, one other project I haven't mentioned that started and it's supposed to be going is we are trying to have a verified compiler from cogent around the LLVM using interaction phase. I know that there is the helix compiler that was put verified and that was exciting. But I'm not planning to port the whole infrastructure to cogent but yeah, I don't know. 
                >> MATTHEW FLATT: We have two last questions. 
>> Hello I am-- U.S. A understand, fantastic talk, I am a client of your tools I'm using cogent and Dargent and they right to this programme and they provide and produce a bunch of verified SQL. Awesome. Then I look at the C code. It is not as efficient and is not as whatever reason I want to rewrite some of it. What is the proof? What is the story there 
                >> CHRISTINE RIZKALLAH: -- and write a half story or write your own C and it will be efficient, and another thing that we tried, it was a student project that still needs to be a lot of development to become a thing. It was having a debugger so that is what all systems folks complain about. They did not like the C code that we were generating but they are like okay I can live with that as long as you can give me the debugger that matches the C and we are came from in the cogent and so that can look at the cogent and know exactly where to link them. So we started implementing and like we have a rough in-home addition of a debugger for cogent that does that. But yes if you want to implement your own see code. And link it with other cogent we can convert it to cogent and converted back. I don't know what else to do with it.
                >> AUDIENCE:   [Laughter] thank you. 
                >> MATTHEW FLATT: Last question.
                >> AUDIENCE:   Nikhil Swamy, great talk Christine, it's great to see this working in the small setting you're working in. I wanted to point out that if you're willing to adopt a somewhat larger TCB, including SMT solver and a tool chain like Estar, there's a great A there called ever partners that my colleague Tina has been building which supports some of the kind of data layouts that you are talking about. Including general raise and things like that. 
                >> CHRISTINE RIZKALLAH: Okay I'm happy to talk about it. It is nice to have as much verification as we can, right? But again is a compromise sometimes of just a group of the compiler term theorem that we can get a higher order logic if we can go a few steps further automatically using SMT solver, versus not doing that all because we don't have the manual labour to do the manual proofs. It all means, something is better than nothing, always. [Laughter] sometimes actually but like yes. I'm happy to talk about it. I'm not sure how adaptable it is to cogent. I'm happy to talk about it because refinement type is much harder to deal with than I anticipated. Because we wanted to provide, to find the types of interactive proofs as well. So bubble up as the automatic proofs as well and then bubble up the rest to the person to prove and that was not as easy as I would like it to be. 
                >> MATTHEW FLATT: Thanks. Let's thank Christine one more time.
