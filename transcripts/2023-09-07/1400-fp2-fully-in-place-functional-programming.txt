-                >>PETER THIEMANN: Okay thank you Simon. Before I announce the next talk we are still looking for the speaker of the final talk of LURK: Lambda, the Ultimate Recursive Knowledge (Experience Report). Thank you very much.
                 So now it is something to be seated. We are talking about fully in place functional programming. And the programming speeches given by Anton. 
                >> ANTON LORENZEN: Yes I thank you can hear me right? So I am Anton Lorenzen, and we are at the University of  Edinburgh this might sound like a controversy at first, because the functional programming is all about persistence and immutable data structures. So how can things be mutated in place a Mac to illustrate this let's look at the reverse function, which you would write in the functional programming which this is in the coda. And in the reverse, you get down here what you see the memory looks like. You get the list X which corresponds with 123. And re-create the know mac you later which is empty, and then we push the first counsel until who this, later and then we do recursively until we get the list 3 to one and memory from acute later. But kind of what happens under the hood is that we have allocated a complete a new list for the, later. And we still have the oldest memory. So maybe this is the last use of the last list success. And because this is now the garbage lecture which is maybe a bit inefficient. So how would an imperative programmer this? An imperative programme would write this. So here you have this memory and consider what happens here. And kind of let's go through this and in a loop kind of keep on setting these pointers and we knew Tate the input list in place. In the memory it is much more efficient and we have done, new allocation. And what we do in the functional programming which to get this. In a way, maybe not so much. We still want to have immutable data structures. So how can we change things if they should be immutable? The very nice insight from the paper and says that we can mutate things if we are the only one using it. And we allocate a new concept, so let's maybe try to reuse the old self. And it will insert for you this general block of code. Where it looks at the reference count of the cell access. And if the reference count as one. It means that this list is unique. And use the cell in that place. We are it turns out in the list is shared. So someone else can still use it and maybe it depends on the data.
                -- it is a powerful optimization you want to make sure that if you add the right function is kind of in the right shape. Whereas the optimization can be done. This person paper describes the optimization really as in the backend of the compiler. In the last topics we want to do is say when we characterise when the function is in the shape. Whether the optimization can take place. And the issue for the compiler will check for you, and really you know we landless optimization. And the creating a syntactic check for checking. So how you do this? We were building on the work by Martin Hoffman's, types of system for bonded in place update. And you get not only the children but you get kind of the space of the cell as well. Of the so-called reuse credit. And then if you want to-- and we can actually show and formalize this whole very small calculus in a way this very simplistic calculus because it's X. And so what this work is characterizing the features, and you as a programmer need to root rightfully in place social programmes. And we have programming wedge and we want to support this. And see what kind of features you need. And the first programme I want to look at is splay trees.
                 Okay they were introduced in the 1985 + and the whole idea behind the splay tree is if you want to look up and want to access an element. You have to move this element where is kind of the description of the algorithm. And once you look at the third and once we're done the third element should be at the root of the tree. And of course if you whole month as traditional functional programming language. It will be terribly inefficient. And kind of like because you change and what we can do in the style. Is we can implement this look at function without doing any allocations. As long as the display tree pass is unique. So how do we do that? Now let's define what a splay tree means and a functional language. That's very simple. But it's either a leaf or a node with a left and right subtree. And the value is here and integer. And alongside with that, we define a zipper, which is either empty. If it's a rude or otherwise it gives you the past down so is either node or Allen if you want to the left or not if you go right. So how does that look in practise. And if it is a node you extract the left subtree letter L. And you create a note L zipper and that contains the zipper that you had previously as well as the value and the right subtree of the current tree. And as you can see this function is fully in place. Because if you pause --pass in the unique sleigh tree you have the node to allocate the zipper in that place. And of course we returned to things that maybe we'd have to allocate the tuple. But actually if you just have a language with a boxing you just kind of return multiple values at the same time. And without doing allocation, actually can also see the code that it will be fully in place because so annotated with the FIP keyboard here. And now this may seem like a new idea that you can write the left function fully in place. But actually that's not the new because even with the zippers, the destructive algorithms on the binary trees may be programmed with these completely applicable and we put the left subtree and put in the existing zipper. So a bit of point of manipulation instead of doing like the implement of the lookup function in the case. We can go down the tree and some way and node into the node LN and let's say we want to look at three. And to do this all replace the node I have the node LI where and left subtree was I now the pointer to the zip I had before the rubric and now three is a bigger than the two and I have to go right and when I do this, I replace the node I had by node zipper. And again I replace the pointer of where the Reds are, the right zipper was. The pointer to the zip I had, and then when I'm at the end, and kind of so much of how the reverse function look. And if you implement it like this you can see that this lookup function is not fit, we have not annotated with the FIP keyboard. Because there's a bit of a problem here. If we call the display and just the left and right separate element three. We can see that the note at the bottom is now you unused weeks we have a delay allocation here. And so if we do it the allocate during this process. At some point we will have to allocate to end up with the same number of nodes. And it will seem as if we now try to implement it from the splay function at this point. The at the root of this zipper that we still need to allocate the root and this is to the point where we have to do the allocation. So what can we do to write this function without any allocations at all? And we need to think about these reuse credits. What is the space that we have available? In the lookup function we have one node that was unused that we would have to deal okay. And here we would have a know that we would have to deal okay. And so if we have a lookup function now. And the last up when X equals Y. Them recall display. We now pass in some data structure as well. And this data structure, just be called topic it's isomorphic to a node. So you can see that it has just the right size to be reused against the opium. So if we want to look at three in this splay tree, we go first left and then write again until we have the node. We would re-add it to the top and call splay with a stop in the zipper we have. And how do we actually unroll the zipper and bring this element to the topic now that slightly bigger algorithm, sorry it is that long, that's also that long in the original paper. And we have the zip in the exact transformation which comes readily from a paper. I mean they did not use a function language but and if the algorithms come from there, but you can see that if we are at the empty root zipper got you can now reuse the top know. For the node that we previously had to allocate. And you don't even have to look at them very precisely because we have the FIP keyboard and the first-line. So you just know it will be fully in place. And if I run this function, will happen now is that I'll bring the top node to the top and then in the case, where it now, in my route, I will just rewrite to the top, and to node and I've ended up with the display tree. And now we've correctly put the nodes to the topic and I've done no allocation in delegation. And this is the kind of algorithms you can ample met with this. I want to show you one more full example.
                 This is merge sort. If you want to write merge sort any functional language you can see that it is often not fully in place. And the first up, you are giving the unsorted li list in the 321 here, and each of the list in the homeless, and the invariant now that each of these single list is obviously sorted because it contains just one element. Now keep emerging the sorted list pairwise and but if I ample month this algorithm like this. We can see that it is not fully in place and it will allocate and there is no way that it will implement this precise algorithm. Without allocation, within the first up I have allocated. I need to allocate all of these single list. I have all of these extra memory that I need to have in the first topic but it turns out that by changing the data structure a bit, you can change what this algorithm is. So we don't actually need a sort of single list in the first topic we just need to keep an idea of where the partitions of this already sorted. So if we create special data contract and that's what we do in the paper. And we have the partitions sublist. And the idea behind this is that we cannot express the same algorithm and so if we have this list 4, 3, 21 and a bunch of consuls. And we have exactly for these constructors with two elements and that means we can reuse them against each other. And on paper we have a bunch of algorithms like this. So like this tree in session and we use exactly the same algorithm as the introductions to algorithms. And we show a quick sort and the finger trees and a map over any polynomial datatype can always algorithms don't have allocation the allocation and they have constant stack usage as long as you pass in unique arguments. But of course you want simply need to create these unique arguments. So how do you reason about this in a functional programme? And you can still use these functions even in a way where the argument is not unique. For example you could write something like this function. And create palindromes as part of this list. Now a pal and reverse are full fully in place functions. And you pass in unique trying that they can. And we have the two users of access, and the reference count will not be on one and no place update will happen. And how can we reason about this? An idea here is that we have added two rules to our calculus. We have one contraction rule that allows you to something that we already have twice. And we have the weakening rule that allows you to forget about something. And it is exactly the two rules that can add nonlinearity to your language. It would not be good to add these two just fully in place countless, because you would have a forgot about the linearity and there is no way that you can do the in-place updates in general. But this should make a lot of sense in reference to the system. Because using something twice got you can just represent by reference account increment, so the step function will increment the reference count time. And forgetting about something, corresponds to reference count decrement. The reference count at one time. So it what we do in the last part of our paper is we take those fully in place calculus and add a bunch of rules. Or nonlinearity or closures. And what you can get implement it by reference counting and what we get is a non-view in the Perseus. Algorithm. What we can see this way is Perseus is a linear calculus for correctly placed reference counting instructions. And what we have new insight into FIP because we can see that if you are in a Percy style reference counting system FIP is kind of the fragment of the language. You don't have to increment and decrement the reference counts as long as you're in the FIP fragment. The only overhead you have do to reference counting is by checking every now and then. Whether you are still with unit unique data. And that something we also see in the benchmarks. So in our benchmarks we compare FIP. That is in the red. Fully in place function programmes we propose in this paper against the stem of that implementations that you would have. And in like the textbook like, you have the standard reuse that is in the yellow and in this diversion of like the typical functional algorithms that are where you would apply these use analysis. And it helps quite a lot. And make sure that we talk about the one benchmark in particular. And what is the team benchmark? The maps over the binary search tree, this means that the benchmark reads analysis actually does not work because the tree is shared. So there is an opportunity for reads. And as you can see is very small got the cost is even small, even if the regionals to actually does not succeed it is not that bad for performance. And the other programmes using these that can't succeed and their real analysis is very good. We can also see that the FIP programme that we have is quite a bit slower than the standard programme. Know this is really because these are two different communications. The standard programme recruit is on the stack. Which means if you have a very unbalanced binary tree. You can map it over and run out of stack space. The FIP programme is required not to run out of stack. This is a guarantee that you have constant stack usage. And how we implement the sludge for example. And manage the zipper that has a bit of that. Of course what we get is a good balance. Thank you very much for listening to this talk. And I hope you liked it. And thank you before I take questions I want to quickly say that we fully implanted this into the compiler language and you can go online and downloaded. Also you can visit the demo at the Microsoft booth today at 1330 and we are very happy to take further questions there and show off our system. Thank you. 
>> This is Ria Rodaski, when I have seen this and other languages like rust or work on notable value semantics, they usually annotate argument of a function to kind of like were you can indicate the type or if something like that. Will hear you change your choice to annotate whole function. Is somehow being in place. I was kind of wondering if you could comment a bit on this choice. Because I could imagine some things that are being updated and others not. So how does that map to the whole function being in place? 
                >> ANTON LORENZEN: That is a good question, we also have the small annotations on function parameters, we can say certain parameters it will be borrowed. That means you will not try to for example return it. And will not try to in-place reuse it. It is kind of like a read-only value. For the full iteration of the function. Yes. And the function parameters for Lake this is something that should be used linearity, it should be something to think a bit like what the trade-off is. 
>> Like they switch the work and they have that and parameters that they use but is very cohort. Thank you. 
>>---. Jones up games. I have gotten a question to do with fragility. Suppose you have a function, actually your splay was kind of a example, which in many parts a lot of the function is flippy right, but there's just one corner, perhaps even unequal path, on FIP so it seems to be a bit all or nothing. And all the juice you can if there's a little corner with no juice well allocate right, do you have that in practise? I'm just worried whether it's in practise might feel is a bit fragile to programmers? They make a small change and you know they don't get anything. 
                >> ANTON LORENZEN: So that is kind of independent of the script work, it kinda gives you a view of one it will succeed but it can also succeed if the FIP check kind of fails. So you will not see any difference in the performance due to that. I agree though that it is really useful for the folks and to be able to quite some of a small amount of allocation. You see this a lot with like the insertion function. Were we do want to reuse all of the elements of the tree but when you're at the bottom you need to insert a new thing. And actually we also do that the paper. So we can write like a FIP keyword with a small one behind it. This means that you can do this function fully in place and you can do one allocation. And then you can exactly used to type something against the session function. 
                >>PETER THIEMANN: So let me interrupt and pose another question. It's related to Edwin Tarik. Me express line X or RC you know mac data operations in FIP or can we implement a single writer multi-reader concurrent data structure? 
                >> ANTON LORENZEN: I am not an expert on concurrent data structures. So it will be hard for me to answer that question. I think I would need to look at a precise example. But yes we can do a lot of data structures so think there is a good chance it could work. 
>>  Yes you could pass on please. And 
>> Hello Sam Westrick-- a fantastic talk and really excited about this work. My first impression is that it is very integrates well with sequential programming. And maybe this is maybe a simple version of Edmonds online question. Book can you speculate this into a little bit of a parallel system? Let's imagine like something simple, like purely functional parallel, you know like what are the challenges integrating FIP into such a system? 
                >> ANTON LORENZEN: That is a whole good question. The whole idea is that we take things when they are unique. So I'm not really sure what the relationship is into parallelism if in the sense that something is unique about you know that it will be only on this thread right, it is no other thread that can hold on to this. And so yes. 
>> Thank you this is really good. 
>> Hello-- Google.  My question is about memory fragmentation. If you have a programme in FIP style and then wherever the nose got allocated then you first allocate they stay forever. But I imagine that a structure like a display tree-- splay tree if you access it many times without allocating anything else will tend to compact the top elements into one region of memory that they can in the cash all the time. When you're accessing them have you found functional place have positive or negative effects on caches? 
                >> ANTON LORENZEN: I think they are probably examples where it does badly in places where does well. And so for example, splay tree you can like if you say you're in a traditional function programme language and you allocate like a big split chain memory, and then you look up quite a few times. And every time you look up, you can reallocate the splay of the tree. And you have like a big spread memory here. Then you get all of this blinds somewhere else. And if you have all this in place kind of because you want the only change things inside this big data structure. Otherwise you can also ask Daan Leijen on this because he is an expert on memory fragmentation and memory allocators. I think that I'm sure he will have a good answer. 
>> Okay so let's go to the two remaining questions and maybe take it off-line. 
>> Jasper Gear,  Tufts University I was wondering if there's any kind of like an ocean for a policy in the reuse case for a multiple space Chris that I might use? If I'm operating on a really large data structure, but I also have kind of a smaller, accumulator. I might want to reuse the it, leaders memory for the human later, to maybe maximize temporal locality I was wondering if you exploit that. I mean. 
                >> ANTON LORENZEN: We always reuse the zipper got like we use the ordinal tree against the zipper and then zipper for the new result. And I think this is more of on the level of the system itself. Maybe not on the authors with the function authors side. The actual, like the compiler. And the compiler could exploit this. 
                >> ANTON LORENZEN: Yes that could take a while I will come back to you. 
                >>PETER THIEMANN: You have a follow-up question? 
>>  A really short question, last one anyway. The user rights the --sorry --University. The programme that the entity is fifth and it turns out they have to reuse, was the experience getting an error like and does it help you make [Speaker away from microphone] 
                >> ANTON LORENZEN: So we have implemented this in the front end of the compiler. So the check is on the kind of source language. And then what the check does is the kind of check the reuse credits. And they say hey this is the code pathway that I could not, we'll maybe did not have enough reuse credit or maybe had to many. Maybe you want to fix that. 
                >>PETER THIEMANN: Thank you Anton.
