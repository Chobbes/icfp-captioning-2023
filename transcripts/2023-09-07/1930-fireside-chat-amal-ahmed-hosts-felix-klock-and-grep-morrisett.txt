			>>  All right let's get settled in. All right welcome to the second last session of ICFP. Oh, we almost had a fire, okay.
                >>   AMAL AHMED: [Laughter].
			>>   Put it on this table here.
                >>   AMAL AHMED: A little fire.
			>>   Excellent, yes now is a fireside chat. Welcome to the fireside chat. A couple of announcements, just a reminder that tomorrow evening we have the FARM the performance evening any keynote and a performance by Gloria Chain, at the rice back auditorium just a couple blocks down the road. So do consider going to that. And a couple workshops that are new workshops. Thanks for you to attend there is one arch on functional programming and architecture on Friday. And there is declarative programming for medicine and biology on Saturday. So do consider going to those events. Now let me hand over to Amal who will host our fireside chat from Northeastern University.
                >>   AMAL AHMED: Thank you and Nik, what are we have here? That start with that the focus to talk about rustic which has been incredibly successful systems programming language. And sort of all the cool work that happened back in the very late 90s and early 2000 and how those ideas built up and hopefully figure out how they went into Rust and what comes next. Let me start by introducing Felix who is a rentable software engineer at Amazon Web Services and he works on the Amazon Web Services and the language design team and Rust compiler team. An alternative cool, things in PL development. And as you put it in 20 years. Put in the oscillating between the static analysis and dynamic linkage technologies. Also done the CC + compiler development and done research on garbage collection and back in implementations and so I'm. Any work done was the all on parallel JavaScript. And then Rust. And then Greg who is the Vice Provost at Cornell Tech. For that he was the dean of computing and information sciences at Cornell. Any he has done a lot of amazing and cool research that is relevant to today's conversation. You worked on the type assembly line which which most of you probably know. And sort of the late nineties, to thousands work on things like alias types, calculus of capabilities and something that actually worked on with him as a postdoc. This little linear language with locations which had a capability type system for strong updates. But a lot of work on systems language design for you know, provide safe memory management. Most important for the current agent today. Welcome and thank you for doing this.
                >>  FELIX KLOCK: Thank you.
                >>  GREG MORRISETT: Thank you.
                >>  AMAL AHMED: We will start this off for Felix, tell us about Rust and why is so popular and what sort of systems programming, what sort of software is being used to go there.
                >>  FELIX KLOCK: I like to think of this in terms of Rust and why's it so popular? I would like to ask lane that Rust group at Mozilla. It was in wars range child the private project but it reach maturity at Mozilla. And part of Mozilla's mission is to ensure that the-- global Internet is a global public resource open and access will to all. And the reason why find that mission statement so relevant to from my perspective I see Rust missions to make systems programming a public resource open and access will to all. And then process is unable a whole new generation of programmers who would never have considered. Dealing with the C and C enable them to tackle systems level problems. And I say systems levels that's what systems programming is legitimate systems questions asked. And the best description is Stephen Kell did a paper called the some more men for C. Onward in 2017. And you're going to do fundamental's that applications are built up on top of and that you have control over low-level details. And maybe you would have thought functional programming isn't compatible with that, I've seen that plenty of talk today for that or are you the Congress. You have plenty of opportunities and fine-grained control if you do it right. So Mozilla is turned off with making a decision at some point, it was critical point in Rust maturities they decided we can deliver a language without a managed runtime something in analogs to C&C. Not a algorithm to Java or Python. And just relying on the underlying hardware as much as possible. It was crucial for being considered for projects outside of Mozilla. It will he could blossom. Outside of the domains that was intended for within Mozilla. And that is how the sort of could even be considered out of their. But that it was Rust decision to focus on number one for safety, number two performance, number three accessibility, as in an enabling anyone to programme in Rossberg of those three things were to go and it was them being successful in achieving success in those other domains outside of Mozilla.
                 I can give examples of earlier on current rough successes if you like but I don't know if this group needs to hear this.
                >>  AMAL AHMED: [Laughter].
                >>  FELIX KLOCK: There was some early examples, actually will bring up a couple of these. Actually drop box when they migrated from using other cloud providers I won't mention whom, they easily want their own content distribution network for how they kind of distribute it. And they implemented it in go at first. And they realise that the cost of this thing was when to be too high in terms of the size of the system they would need to deploy in this kind of solution network. And they realise that they took one of the components and rewrote into Rust, they could deliver this thing and it could cost, you know, much lower.
                 Likewise there is a number of other things that have been delivered more recently. For example the Internet security research group, the proximal Project there is sponsoring work on making Rust available in the Linux kernel delivery curl with Rust or SSL alternative like Russell's. And likewise a man Amazon Web Services investing using Rust and various critical components. And the reason my mentioning this is to make the point that in many of these cases that the reason why Rust has been successfully deployed is because they don't have to rewrite the whole thing and Rust. They were able to replace the individual components. That lack of managing runtime is so important for them to be able to do that. So people often make a joke of how commute, some particularly eager Rust evangelist will go around saying rewrite it in Rust, rewrite it in Rust! And I want to make a point that is actually a misnomer. You don't want to rewrite your whole system in Rust at least not at first. Got the parts that need to be rewritten and do it on your own and deliver something successfully. It is a big part of how this is been able to work out. So yes and the final thing is this whole generation of programmers to deliver successfully. Rust court is the expressive type system + access to unsafe features. And that enables a couple different things. Number one it enables library developers to deliver new abstractions. Outside the Rust library standard, that these systems for example the rayon parallel is a library that ramp might what silk did, decades ago in the context of Rust. Now on and do it in the way of a safe is to be in on your computation across the concurrent cores and we were you don't have to worry about the managing of your memory by hand. And likewise, there is basic programming constructs that have been innovated outside of Rust standard Library and has been enabled by Rust providing access to low-level unsafe programming details. Meanwhile, Rust safety guarantees enabling application developers for lack of better word, play. They can really try out new ideas for design for concurrency and have the compiler help them find out where they got it wrong. And making sure that the obey the rules about avoiding immutable shared state. You know having aliasing in the wrong places. You know literally within the Rust compiler itself in places where you try to paralyse things.
                >>  AMAL AHMED: Okay so we will connect to a lot of those things and talk about them in more detail. I kind of want to go backwards into the 2000's and ask grade, so can you give us a sense of mindset at the time like people why were they pushing on systems languages and what ideas were they pushing? What were the goals and so on there that worked and didn't?
                >>  GREG MORRISETT: Yes, 20 or 25 years ago we were starting to work on this I mean even going further back. You know 30 years ago. There was this dream when I was that Carnegie Mellon and further going back 30 years there was this dream that when I was at Carnegie Mellon building an operating system and standard. Of New Jersey no less and we got as far as building TCP stack and it was really crappy it wasn't great language for writing us. The fox project but you know, we were all supremely disappointed that the critical code that we depend on kernels, databases, networking stacks and all of it was written. In letter C and you know. And it was about that time when everything was going to get wired together. On the Internet and you know the bad guys were starting to brake into stuff and it was actually having real damage. There was this desire for the language world for safety. One mode, that was this all rewrite your code standard of OCaml or Haskell or whatever you know. I get frustrated because those action were not good language is for writing systems code. And so we thought all we should make a language, we should head toward 80 language that systems people would have adopted. And the other 2, one was the control over the data layout. And that is pretty easy to get integrated. The hardest one was garbage collection. You know, how do you get --thank you, garbage collection. So we just stole some ideas from Martin and math talk and other people who had built the ML kit compiler. Who you know top ends and top ends work in regions. Give us a way to have runtime without garbage collection. And so that so we get started, they were not as smart as we were, so we did not type inference or anything like this so that sort of implicit the manage memory and we were making a very explicit. So that is how we get started and the goal was, you know ideally to replace it, people writing systems code any language that gave you memory safety, we get call it that, we call that safety. We did know what it meant. It was safer. Check the rebounds and it checked other things in the type system that was quite, quite, you know interval and important for checking and catching most of the kinds of common programmes that letter C programmers tripped across. So that was the intent anyway.
                >>  AMAL AHMED: So what worked and what did not? [Laughter].
                >>  GREG MORRISETT:  [ Overlapping Speakers ] will regions don't work, regions are basically they are lexically scoped, so you sort of greet them. The nice thing about them was their containers. So you could abstract over big data structures without knowing individual object ownership and lifetime and stuff. And you can pile them all into a region. And DL keep that region. And there is something nice about that. It is on comparable to the garbage collection. The region typing discipline allowed you to collect things that a trace and collector wouldn't collect. And vice versa. So it was incomparable. But in practise it leaked a lot and it was painful to use. So we had a lot of other things because we added support for unique buyers --pointers which were find types and the integrated with the regions and allowed you to do things like taking a unique pointer and giving a lexical scope and giving a name for the region and then essentially borrow it. That's the terminology that came to the line. So that you could really duplicate that pointer for some, you know, scope and be guaranteed by the typing system that by the time you get back to the end, you would regain ownership of that particular unique pointer.
                 But this wasn't integrated smoothly. It was kind of a hack. It to give the ability to have first-class regions, regions that did not have to basically be scoped anymore. You could do a lot more with that. And you could use it for individual objects. But we did not have static analysis type states. And things like that, that Rust has to make it ergonomic. And we made you programme with swaps. If you had a unique pointer you had to swap in and out of everywhere. And boy was that painful. So it was kind of their, there were a lot of the ideas that were you know, lifted from password and all the way back to Gifford and company. But you know what we can get back for it. And we didn't try to tackle concurrency. Will Dan Grossman did later on. But it was a very coarse- grained approach towards concurrency. And I think in the magic of Rust is it really got fine-grained ownership discipline coupled with the insight of yes, don't have threads sharing mutable elitist state. And that was a really brilliant design.
                >>  AMAL AHMED: So I was going to lead into like which of these ideas influenced us later, but Greg already has started on some of that.
                >>  FELIX KLOCK: I would say basically everything that Greg just said ended up in Rust in some fashion or another. Although type state we threw away and you evening coded some patterns of type state and there is were many ideas that were in Rust and it reached maturity and we threw some out. But one particular interesting part of the history, depending on your point of view, is that it had unique pointer is. The linear refined type things from the basically outside regions in terms of static notion of having represented the function signatures. That was only added, not late in the cycle it was something that Niko Matsakis came in and a sickly have the insight of saying look we've got basically at the time Rust started off with this kind of question will system. Where it didn't have references as a first-class type constructor for many years and is development. And it was something where you had it parameters your passing around to functions and it would just sort of have to, the calling dimensions of system would sort of figure out, oh well let's try to pass by reference to figure it out when we can work it out. You end up with a system that looks like the region based, you know, strictly nesting lexical scope type thing that you just described. And so Nico was the one that came in and really had this strong intuition and insight, would everyone took hold of saying no let's make proper references a first-class thing in terms of being a type instructor and essentially adopting much of what cyclone had pioneered.
                >>   AMAL AHMED: What is the data risk freedom? When did that come into the picture?
                >>   FELIX KLOCK: She wore me about this question I have time. I joined the project when I was a much and development. I had to do some archaeology to figure this out. You can go back and get the repository and try to figure out where the data rates freedom came in. But you discover the term data race did not appear anywhere in the source codes are the docs until 2012. But that doesn't mean anything. It is just a what I can tell it was order to prevent data races that was always part of the story in some sense. It was mostly question and the outside. The earliest thing I can see in this notion of some think shared visibility concurrency. I don't know what that means so don't ask me. But even though data race freedom was part of the story. It was a question of how do you compliment? And it would not have worked out and practise in terms of the marketplace we have now. And having your OS level processes be your level of isolation, things like shared state can't be mutable and has to be immutable shared state. You know people will explore but that reality isn't just good enough. And you know if you want to have sort of an array and place and do it in parallel, you've kind of got to in some way taking, talking about that thing being mutable and partitioning it up into mutability into things that are partitioning.
                >>   AMAL AHMED: So sort of high-level, in terms of intuition, what is the key thing that cyclone did not do perhaps? You are talking last week Greg how cyclone track and variance is not quite temporal properties. Like is this the key distinction of what makes Rust more expressive?
                >>   GREG MORRISETT: Yes it is part of the interface. I was coming from the functional world where you think about values and types as and variance basically. And so, and yet something like screening and object is inherently breaking intuitionism, right? You're just getting rid of something. So we were always hiking against imperative code in a sense. Because we were grafting functional programming ideas onto this horribly imperative language. You know a good example is just tracking any pointers through a programme. We just did not, we just made you swap. Right? But if you did a flow analysis on the code then you could easily check, you know, are you duplicating a reference or something?
                 And we just did not engineer that way. And I think it was just because we were coming from an ML mindset as opposed to what you would naturally do in imperative language, you know, from the beginning.
                 But another way to look at that is if you the sugared the imperative linkage back down to something like TAL you would see that the imperative code it can be represented as functional code. That is and continuation passing style, changing types of the local variables as you go along. So we always had that the back of our mind. We just were not very good at syntax and flow analysis. Design that makes it something that humans would want to read and write.
                 I mean to tell you the truth we did not really care that much about usability. Because we were still --spee01 but from the perspective of sea programmers you wanted adoption.
                >>  GREG MORRISETT: We did we had all of these grand goals. What we were more interested in the weird typing interactions. Dan Grossman uncovered a really funny, unsoundness and was the interaction of the & operator works you can get a pointer in the middle of a record. And it was a really funny, bad interaction with regions and that operator. And is the kind you would never discover anything so language. Because who let's you take the pointer into some middle of imperative data structure in Haskell and ML, right? So there was ear weird interactions with that and  Existentials work and or regional regional work that were interesting. And we kept trying to uncover that. And boil it back down. And there was later work with you and also Matthew fluid, that to get the essence of this there was a paper about one attic regions, that were we ended up connecting to run ST and Haskell. Because there's just regions and then Oleg took that and ran with it somewhere along the way. And there was just this really interesting types of theory I think between ask lane he regions as the capabilities and the connections between monads, a fine types and linear types and capabilities in all these ideas that were floating around in the air. And there's a lot of good work that came out of it. I thank you saw some of it today still carrying on that tradition of trying to integrate control and types and so forth over moving beyond types as and variance to types as capturing changes over time in the programme.
                >>  AMAL AHMED: Go ahead.
                >>  FELIX KLOCK: I think that was for good. [Laughter].
                >>  AMAL AHMED: Okay let's get into lifetime. So how did Rust come to adopt lifetimes, I'm curious? And how do they connect to earlier work on regions? We touched on this a little bit already. And then I will get into my other question. [Laughter].
                >>  FELIX KLOCK: I did this archaeology in preparation for this. I'm not going to attempt to go over all of the prehistory here. Except for to sort of repeat that the original designs for Rust they did not have a proper reference type, you know something where it was very much expected to just a parameter passing and the system saying oh well, something of this type, being passed as an argument. We can, the compiler might choose to implicitly make it a reference. And then the programmer might actually have a hint. Saying own over this parameter we will say oh yes this should be passed as a reference. I was will checking with Nico because I said hey what happened if it couldn't be passed the reference or the programmer added that is it going to be rejected at Mac and Nico said no, I think actually just make it copied anyway. And some of those level cases. Just definitely the kind of like an ad hoc system that would let's have some question will guarantees or lack thereof. And it was like when Nico came in and said let's make this proper type constructor. That was really where we saw the decision to say, let's add Nico's choice the worldly region. Where we use the word lifetime. And then Rust to talk about this. But this idea of having denotation static you a notation for capably of and the temp oral bound and escape ability whatever it might be, saying this reference is guaranteed usable. With these keep abilities for at least this length of time. It might be a last longer. It is not guarantee that you know D allocated from the end of the lifetime. But it gives you a lower bound. And Nico recognise the amazing things looking at those post. And you can look at even though then in Nico's post, in 2012 he was talking about then and the fact that there is some typing means there will be variance property. Because Rust had generics start from the two. Because recognising that this will be in variance in respect was parameter type parameters to a suitable its movable thing and there's going to be covariance relationship when it isn't mutable. That can of thing was recognise that the out that. That is really when lifetimes came to being. And the only question is then what is the model for what lifetimes are? At least radically. At that time the model was they correspond to something like the structure of the AST. Right there the tree structure that is present there with some small details. So that is not all we have today. We have some a little bit more expensive called lexical lifetimes. Because essentially it is too limiting of a model to use. And it does not capture enough of the cases that programmers need and practise. And one to my mind, interesting detail here, and in Rust we do care a lot about ergonomics and understand about the diagnostics of the programme. And one of the points of view that I think I was raising at this point time was being discussed. Well isn't the parse tree type model. Not parse tree, AST is this an pertinent distinction. And it doesn't make simple for people to understand terms of being an obvious nesting structure. Isn't that easy or wait to talk about things?  And the simple truth is like no. It is up being somewhere got the thing that you want is to reason about, what the former cares about is the disruption of what is the problem that is being caught by the compiler? And when you give them a presentation of the form that is not of this parse tree does not match Max rotations and that doesn't help them. That's like no, you took a reference here, 70 else did a right here and yet another access here. But kind of three point presentation. It becomes apparent. So yes this is wrong. It doesn't work. And so I think that was really another critical thing. And that was part of what came out of the lifetimes is recognise trying that presentation is the right way to think about it.
                >>  AMAL AHMED: So I'm going to sort of ask think people still struggle about the lifetimes and what they are at least in the semantic sense. At least starting took about non-lexical lifetimes. My group has been working with this formal semantics of Rust. Called oxide and is something that we've had to struggle with as well. And I think I'm not sure that I have a clean answer. And in fact, I know that Nico calls them origins in his work on: Yes. And I'm sort of curious as to whether either of you have a nice intuition, simple semantic intuition or clean answer for what are the lifetimes?
                >>  GREG MORRISETT: It is very connected to capabilities but languages and types don't get along with capabilities well without moving into some structural framework. And so you, you know, but it is very natural to want to say, here's an object that today I can use it like this and tomorrow I can only use it like that. And you know the types and functional programming hack this by building new things. That have that instead of this. But you don't have that luxury when it comes to memory management, right? And so you have got to go from this is a valid pointer to this is no longer a valid point. You can't reference it anymore. And so and you can't play levels of indirection tricks. Or other things. It is the real litmus test for do you have capabilities? And you know there's a lot of work, people are trying to do that in a way that is ergonomically acceptable. And then Rust is really the first time that I have seen people buying into that. And actually, I think that back. It is very easy to do this. When you don't have alias saying. Right? It is very easy to track, date changes and so forth for local variables and that sort of thing. That's very easy. And a lot of people think that they have rediscovered that and solve the problem. But they don't understand that it's really the spaghetti mess of pointers and aliasing coupled this desire to track changes in state or time. That is the root of all evil. And if you can band aliasing, you are done. If you can ban state changes then you're done but these two things come together all time.
                >>  AMAL AHMED: Is remind me of when I was a Gretchen and Andrew Powell who was my PHD adviser, who said to me one day, aliasing mutation is like a full employment. For researchers. [Laughter] I think that one continues. Okay so I'm wondering if we should talk about non-lexical lifetimes a bit more? Do you want to get into like why these were essential? Patterns of code that you think--
                >>  FELIX KLOCK: So like I said there is a number of patterns and simple examples would be even if you just had another local variable and you borrowed it and stored into another local variable and had some access or some sort of mutation of that second local variable. Well it's scope conceptually extends into that block that is declared in. So if you are stricken yourself to this like match the AST style of thinking. Then now the other operations on that first local variable will be disallowed to say oh, you still have this other thing in scope. And that was like one of the most obvious examples that was used to argue for not ask for lifetimes. Now is not a great example because there is a great workaround were if you say in that case okay you actually silly at another school. Yet another curly braces into actually limit that second local variable isn't used at a certain point. And then add your mutations of the first local verbal at that point. And yes, that case works there. But there is other examples and we lay them out, with no at least three, I think there were three big problem cases that we first introduced when we first talked about non lexical lifetimes. For example if you have a hash table that you look up in. And if you want to insert something into it. If you don't find an entry. Select anything and if you were in the, there was an entry there. Great, do whatever you want with it. And if there wasn't an entry there, you know in the match statement or the match expression you are in some match arm. And in the scope of one that match arm is executing, you have still borrowed the hash table. And so even though there was no entry there, you are not allowed to mutate the hash table with let's go. Because you are still within the scope of one that borrow occurred. So that is the sort of other go to example be like this is where you need that notion that's control flow since it. To say look, at this point we are not going to do anything else with a hash table. On that. In terms of the original borrow that was used for the original look up. And there's another example where there was a standard workaround that used lexical lifetimes in terms of saying okay yes return a value back out of the match exception and then interpreted in order to figure out what to do in response to update the hash table. It was our standard answer when we have people encounter this public. And they are like well forget you guys, I will go back to C if I do nonsense like this to make my programmes work. So that was another key example that was said okay, we will handle this case as well.
                 But there was a third problem case that was similar to the one I just described. And the reason why mention it is because we sort of laid out, these are the goalpost we have and we went in and will mention something and it was pretty, located and it involved in particular subtyping relation that was location centre. And we tried to run and it got something working. But it was dog slow, we could not get this thing to run fast. And realized we wanted to hit the release date, that something had to get. And we said you know what this location sensitivity for the subtyping relationship only handling is third problem case and we said you know what? Let's draw back on that. Is not delivered the full picture hearing for right now. And so none of the lifetimes they currently stand Rust today they handle only the first two broad cases that I describe that I sort of outline. Out the third problem case, all I mentioned in Wallonia is, basically Polonius that next is like the next . Jen borrow checker that Rust work is people are working on for Rust and handling these cases. And lifetimes can only that third case does matter and we are trying to get it to be that third thing that we use in the compiler at some point in the future.
                >>  GREG MORRISETT: There is another compiler at some point. It's the calls for data structures. I think that Martin worked on the region resetting in the MLK compiler. You basically have a loop and you want to create new data for the new iteration of the loop. And you want to collect stuff that you generated in the last iteration. Try to do that with the lexical scope or write your code and the continuation passing style and you never collect anything. That is the problem with lexical scope lifetimes. And so if you don't have some mechanism, you are definitely going to have problems. And so yes and cyclone there was this hacker you basically had an object that was an  Existentials a region row, and a pointer or a handle a capability for that row. And that was linear or a fine. And a data structure that allocated in that region. So that's all you would've handled that hash table example. And the price paid was that hash table not to be linear, you have to have this unique pointer that you're sobbing around and stuff. It is a pain in ass the.
                >>   AMAL AHMED: All right, let's have a talk about-- major feature of Rust and I'm curious as to when got was that part of the picture from the very outset when -- was working on Rust, or was added later? How vertical do think there.
                >>   FELIX KLOCK: It was always part of the Rust design at the outset it was like one among many parts of its affect system and I had originally they were like rated and had some pretty and bit his ideas. And how much fine-grained they wanted to put in the language and analyses they wanted to put in the language. And simply reality here is that it matured and we sort of,  out features to order you know make the things simpler or whatever. We eventually realise we don't need this many effects. And you know, the other crucial point when I was doing this review of the archaeology here. I was struck by the fact that the early versions of Rust, it was a very coarse notion where I was like okay, the whole function is declared as being unsafe or not unsafe. And then the function is declared unsafe, has to be like run on a dedicated OS, instead of the OS offices that have been deemed really hard to run lines in the sand, and how we' re going to isolate these things at the time. I suspect the gradient was probably taking inspiration from Erlang and stuff in terms of wanting to have level of protection between pieces of the system. And that isn't where we are today. We have instead unsafe blocks, we can get very fine-grained limitation where you can have unsafe activity where you can operate on save on Rob pointers. And I think the piece to recognise is this wasn't a matter of like oh, do we abandon a more complex type system to end up where we are now? I mean there were some types of components that we were abandoning. The more important thing is we were abandoning these complex runtime support features. And were basically saying look, we want to be able to target like, don't want to rely on the OS to provide the stuff that we want to be the OS, we want to be the thing that inputs the OS. Much like Greg was talking earlier. Mozilla doesn't make operating systems but they make web browsers. And he was exciting to me when I was for talking, and like a browser is at least as complicated as an operating system. So you want to be realistic about complementing one, you need a language that can handle the operating systems.
                >>   AMAL AHMED: What was thinking about something like the say code back in the day of the cyclone? I mean with us have been just like know we are never going to do this because then we are not?
                >>   GREG MORRISETT: No, we had a block that you could label C and you could write C code and it was necessarily bootstrapped to the get a library's. I mean how do you, I/O or anything like this so Trevor Jim had written this very sophisticated pile of code, to adjust, one of the bad design mistakes we made was trying to make it easy to proceed -- for C programmers to look at it and think that it was C. And that they could reasonably port their see code to cyclone. This is not true even though it is one of Nik Swamy's of heroic efforts. So we would and just headers. Because anything about standard IO.H, Holy Crap, you know what that drags in? It drags in all sorts of headers struck definitions with GCC attributes that are attached to it with very specific, it is a nightmare to parse which Lester actually makes sense of. On this at the time it was only GCC that really could taken somebody like the linear headers.
                >>   FELIX KLOCK: It was the G code that calls on the GCC and runs the result binary.
                >>   GREG MORRISETT: Yes but anyway we wrote a lot of stuff there and then built wrappers around the basically every letter C I recall. You know like you could actually call something like stir copy and cyclone and guess what it was going to be bounced check.
                >>   AMAL AHMED: The wrappers were doing that checking.
                >>   GREG MORRISETT: The wrappers were doing that and there was a lot of tooling to make that possible. Is what Felix was saying is not rewrite the whole application. Ideally you can take one module and port that cyclone and then move on. But it did not work because we changed representations. We have fat pointers for a lot of stuff. If you have fat pointers then you know all better off. So in terms of compatibility with things. So yes there was a lot of hacks.
                >>   FELIX KLOCK: You don't have a way of saying like this thing I want the C representation or the other thing I want to cyclone representation? 
                >> GREG MORRISETT: Yes you could, but you know it was painful to you know that's just a fat pointer turned into a structure with 3, three fields.
                >>   FELIX KLOCK: Yes doesn't hold the problem.
                >>   AMAL AHMED: Let's talk about unsafe code guidelines or what used to be known as unsafe code guidelines.
                >>   FELIX KLOCK: Yes the working group format, the team formally known as the unsafe working rubric.
                >>   AMAL AHMED: Yes.
                >>   FELIX KLOCK: We have known for a long time okay [Laughter] I will start with a small anecdote. I got up on stage at some conference or whatever. Some years ago. And I will try to explain about how great Rust is etc.. And someone got up and after the question and answer time, and said what about the memory model? I said well we have these references got you know the safe code is kind of all handled it is fine. And they said yeah but what about unsafe code? Like what are you going to do about the interactions there and I sort of stared and said oh...hmm...hmm. So the reality is [Laughter] that we have a very real problem and that is what are the rules dictating? What kind of codes are legal in an unsafe block there it sometimes sort of sounds like an a trivial question but is not at all trivial because the whole point is that an unsafe block that runs, when you get at least from my mental model of how it's supposed to work. When you ask unsafe block you should reestablish all of the invariance that the Rust is always exciting to hold and it's like okay what are all of those invariance? What are those things that you are always supposed to adhere two and it is not something that we can have a compiler tell you ahead of time. It is not a decidable problem. And so that is the heart of this. Is okay what are we going to tell programmers about what the rules are?  And since the compiler can at best link for some things that can catch all the problem so who is going to validate that they are actually gotten it right and so simple truth is that number one all the rules have been clearly spelled out. And not that we are still enumerating the questions and answering and then tried work out what those answers are. And so there was an unsafe code guidelines working group and they still have an issues list that harkens from those days. And since that's been upgraded to an operational semantics team recognise and importance of this work. And one of the most quickly elements in my opinion is this delivery of some kind of tools and validating it whether your unsafe code is anywhere close to being valid. And that is basically the main answered this is the use in practise, that Ralph saying has this memory model for unsafe code and terms of saying look, here is what Rust references saying his will to happen. When the rules run at runtime what is legal in the terms of the relationship of the different pointers and that you've taken from the different references that you've taken from raw pointers. One is it legal? Is it legal to turn them back into Rust references? The most crucial element of this is in addition to writing out the papers of's operations semantics that you can get an reason about as a human. In addition to that, Ralph has implanted these things an interpreter. Where it takes the intermediate presentation that Rust has entered into a compiler and it interprets that. She can actually get dynamic checking in this interpreter of whether your unsafe code is following the rules as well has currently devised them.
                 And this is so radical that we have tools like this because we can't expect human beings to figure this out on their own in the current state. We can't expect the rule improving community to figure out how to improve the stuff because we don't even know what the rules are yet. There is work in this space, on the Rust improving programmes and Rust I love them to even handle the unsafe code. And a lot of them start by saying we only handle the save code and essentially validates satisfying wherever the properties are trying to prove. So the crucial point is that I want to make that we have the need for the tools here. And then we have like I said it's an interpreter, which you might merely then say it's dog slow and you are right. But more portly the biggest problem is my opinion with Mary is that we've been talking about how the point of Rust swap in module by module and link this thing with other foreign code, would you do with Mary when you have foreign code that you're calling out where you are anywhere now pointers are being flowing over long. And have the extra tag bits attached to them like the representation does in a match with people foreign code has. And what Mary has, there is a fixed list of foreign functions and that knows how to interpret it. And a handle those. And this not one of those oh tough luck, you are interpreting to reject your programme and it reaches a call to one of those things. I've been spending some time on this earlier this year and prototyping something similar to tool. I'm not trained to advertise my tool because it is not ready. [Laughter] but the more important point that I want to make here to all the people in the audience. There is researchers here, this is an area where we desperately need innovation. I know there is, I've had talks with other researchers who are doing things like, there is and LLI, Al all VM interpreter of the LVM byte code and they are similarly trying to take Mary and do it does on LVM by code and also get interoperation that C. And you have to have access C code to compile it.
                >>  AMAL AHMED:--
                >>  FELIX KLOCK: I'm telling you if you find this interesting there is a place for you to help us.
                >>  AMAL AHMED: Okay let's and by talking about, so we've been talking all of this research from like 20 or 25 years ago has perhaps influenced Rust, the successful PL language. But does Rust mean that we are done? Or like to sort of closed but you know you guys sharing thoughts with perhaps the students here or the junior researchers here. Like what are the open problems that we still need to tackle? Or are we done? This is PL, this is it? [Laughter] or is there pain points and Rust that need addressing or would you do something different?
                >>  FELIX KLOCK: So we are nowhere near done. I don't even know if the answer is the ways to improve Rust versus just recognising, you know what we will need in induration language be on this.
                >>  AMAL AHMED: Yes let's do the next generation I was be on this.
                >>  FELIX KLOCK: My go to example here is that I spent months early in my time at Mozilla time to answer the question of how do I make Rust programmes that can interoperate with a managed runtime has a garbage collector? And try to figure out some answer for what to do with, when you have a coverage collector that can do things like in particular it not conservative one. When I can actually move objects around in response to collection activity. And basically the answer is, you are hosed. I mean Rust wanted to have support for GC's and it's really design. But as it currently stands, if you have these references, and they be cast to raw pointers. And those can be cast to managers and you can't move this thing around and more, and the only answer is to pin in some fashion. Which yes, you can do that. But it is not the right answer in my opinion. That is my first sort of go to examples in something that we are not done.
                >>  GREG MORRISETT: Yes we talked earlier about why a fine and not linear, right there because I had always hoped that we get a fear about that you know, there is no leaking. But things like exceptions you know, really as soon as you try to throw that into the world. You pretty quickly concluded that strictly linear is really hard. Really constrain. And so, I still think there's a lot of room for maneuvering and language design. Looking at some sub structural things and capabilities to get stronger guarantees than around the memory management just that you are not accessing it dangling pointer. So that's easy.
                >>   AMAL AHMED: A has to be done economically right?
                >>   GREG MORRISETT: Yes that's what I mean the other thing is that the great thing about Rust is the attention to interface and the error messages and the explanations to people. And you know, if you're going to get more sophisticated systems then has to I think a it has to have a tenant machinery for communicating back to the programmer what is going wrong. And there is always work to do their. And that interface.
                >>   FELIX KLOCK: Yes, I agree with all of that. I think that one of our sort of tenants within the project and that vein and that we treat even error messages confusing to a user. That debug. If people open up issues thing I don't know what this means and we don't see this, listening and you are right that's a problem. If you can't understand what this says. Our problem is and so yes I agree with the need for the work there. And I was struck by some of the talks earlier today talking about the different ways of interpret contracts and the gradual type of systems terms of the kinds of feedback you get depending on the semantics and then that you are applying to them. We don't have contract system in Rust today. But is an area of research that I think we need to think hard about and need to see their especially in terms of the ergonomics question.
                >>   AMAL AHMED: You would take the performance bit.
                >>   FELIX KLOCK: One of the points and the viewpoint of the talk earlier today that I saw that it was look your contract system is set up and it will just single fall and that you debug it later. Maybe we reduce the problem entered on the expensive machinery. I think, personally, my workflow for a lot of the time is to run under a system like RR that can capture traces and replay them at full fidelity. I think a contract system that basically did not take the hit at runtime. But then when you run under a system that you capture the traces and then apply the contracts during the replay. I think it would be a really crucial element of making that your relevant at that point. As far as I can tell no one has investigated it probably because racket is listed everything that people go to on doing research on contracts. And racket doesn't have support for the record replay type systems yet. So there is an area. People, maybe attack.
                >>   AMAL AHMED: All right, I have thought about it but it seems like a no go because at runtime you don't want to do that. But you are right in a replay system it would be valuable. In the time we have left a think we should open up to questions if people have questions before we conclude. For Felix and Greg. Yes please.
                >> AUDIENCE:   [Speaker away from microphone] interested in the different ways that you inform those decisions. So obviously there are high-level principles like safety without garbage collection. And there is this specific applications like Servo that you might use to inform us early on. But I am curious if there is lesser known sources of inspiration that used to make those other 998 decisions?
                >>   FELIX KLOCK: I guess I will be the only one that can answer this huh? In terms of the answer here for Ross, we have been pretty ad hoc in terms of the decision-making processes. And if anything my current employer, Amazon, one of the whole things is to have a set out in schools and set up tenants for teams to follow. And I recognise the value in having a set of tenants that help you make decisions in terms of like a prioritized list of things they could just reference and be like no, this is the reasons that we can sort of justify this particular decision. And how we went this way.
                 So I think my quick answer to you is that I believe there is some unspoken tenants that we all, but the number of the team members have digested. And yet, we have not taken the time to write them out and agree upon. Nico has spent a lot of time trying to write out some tenants and then the rest of us say oh yes those look right. But it is hard. It exactly quite hard if you want to do it in a way that is useful. Like it is easy to write down platitudes where everyone can agree on them. But then the platitudes when you look at them later and say you have a decision to make and say it now these help us. So yes I think, decisions, there are 1 million decisions and I would like a better system for us to actually make it explicit because that is the only way it skills to other people. Right now we are relying so much on institutional knowledge amongst these old-timers who have been with the project for a long time in terms of carrying on. The values that we thought were important.
                >>  GREG MORRISETT: I think, there's two different kinds of languages though. Like there is okay Rust we want that to be used in the real world. [Laughter] and then there's a lot of academic exploratory languages. We are, I don't know we just through the kitchen sink in to see what worked and what did not work. And the exploration was a lot of fun. But we never really had, I remember talking when I was visiting Simon at Cambridge and I think it was Tony Horace who said to him, oh no GHC has become so successful. What a disaster because now you have to support all of this and is a lot of work. And so I was kind of grateful that we never had a lot of users. Because it allowed us to make a lot of stupid changes. And I think in the research prototype languages. There's a lot of value in just frankly trying stuff and seeing what works and what doesn't work. And kicking it around. But you can't do that in a production well. I thank you have to be much more principally driven.
                >>  FELIX KLOCK: But also without a lot of users you won't necessarily know about the things that don't work, right there need that space of active users. And Rust was lucky in that we had doing this archaeology I was struck by how fast that things moved back in 2010 and 2011. We really were changing the thing dramatically from nightly to nightly. One of the things it was referencing in the 1.0 release saying yes, lead up to it saying our current users were used to the fact that their codes and brake regularly every time the updated. And so I guess sort of thing, I agree with you on one hand that it is useful in a research setting. To be able to iterate quickly. But you also have to get that thing in the hands of as many people as possible to get the feedback to inform you.
                >>  FELIX KLOCK: 
                >> GREG MORRISETT: That is a good point.
                >> AUDIENCE:   Hello Charlie from Imperial College London. My question is C can be seen like entirely's unsafe and like if it doesn't ever have to hold all of these invariants and Rust has brought the percentage of the programme which is on save from 100 percent down to five % or whatever. You mention an extra language, do you think in the future the percentage will ever hit 0? Do you think like you can get the systems language where you can write an operating system? With no one safe code all. Like if the work that Ralph Jang and Rust Belt are doing is an incorporated into the compiler? So you could know prove the unsafe code still holds the invariant.
                >>  GREG MORRISETT: What you mean by save? It is not so hopeful when you have a kernel panic or whatever and there was an array balance check. And it was out of bounds. There was a lot of stuff that was dynamically checked and just failed. And so you know, the long-term dream was that you would actually reason about your code and prove correctness and you know when things like concert seL4 or came along you are like okay well that is going all the way. And so I think some attention shifted away from what we mean by a safe language to okay we will verify certain properties, correctness properties of particular piles of systems code. And that was a great advance that we stepped up at that level. And that was desirable. And actually you could imagine were a world that it isn't anything which that's a save as Rust. But it's easier to reason about improved formal properties of it. That would be a different design direction to go and. Then trying to capture in the type checking and the compilation framework for the language itself.
                >>   FELIX KLOCK: My response here is first I will try to answer Greg's very specific question what you mean by save? Actually had a pretty strong debate with a colleague of mine earlier this week about this very topic. To me, there's a pretty simple implication that you want to hold. Namely, if a programme is save it implies it has no undefined behaviour. Right? So that is a pretty simple one. But the argument was about this is bidirectional got a programme with no undefined behaviour always say to make an argument I made is that is not decidable, so that is a bad definition of safety. I want my safety property to be something that I can have some way of identifying the say programmes in some fashion. If you want to get to something where the programming language is one where there is no unsafe notion all got no and trusting human being of the reasoning being the thing that says oh yes thing doesn't have an undefined behaviour and never having anyone in the pipeline that you are trusting that humans raising their. And thank you are at that point thing about the theorem improving. And I think that we are approving the state of the art there. Until it actually reaches the point that the average programmers can make use of their perverse and maybe that's how you get to the semi. Even if it's having generative AI produce the programmes that are provable. Maybe that's what we need. 100% safe and no one safe box at all.
                >> AUDIENCE:   Thank you.
                >>  AMAL AHMED: You will take two more questions.
                >> AUDIENCE:   In many ways you to directions and the rest community and have people coming from high-level languages that want to do low-level programming and you people coming from the lower-level programming that want to do you know get higher. Have you perceived a tension between those two as Rust evolved regarding that? And did you add the tension and cyclone before where you hold a bunch of--?
                >>  FELIX KLOCK: I don't know about tension, I thank you are definitely correct that there is these two different committees and one of the lorries about Rust is as I try to say earlier is this focus on accessibility. For exhibit to read our documents, the Rust book, it spells out for people with the stack and heap are because it recognizes that we have the audience it was talking to, the background might be in linkages that don't make that, those notions apparent. So is not tension per se but is something where we recognise that there is some education that need to happen to appeal that audience. In terms of the other side of that coin, the people coming from C/C + + or the systems, languages. I think the main issue there is how to meet them where they want to be in terms of expressiveness. It is expressively things. Like as an example, we still can't actually express all of the things that C can today. But is equal to get there. Or to be able to write down, anything we can write and letter C we want to see if we can be able to write in Rust as well. In some manner. So that is pretty simple goalpost as you can imagine you say that once we get there there's any future see programme writes down in this the way programmes corresponding at and would satisfy them is a good goal for meeting. And the things that they can express, we want to try to tackle that domain as well. Up think that is the main tension comes from if I made him fight anything. Because in particular with the C + + programmers heater talking about the object dispatch model and how you represent the classes and ritual method tables. And that something where Rust has virtual method tables. But they are not compatible with C + + and that is an example of a place where I think there is a gap and it is an open question, how much work you want to do to reduce that gap. Versus putting in the third-party libraries. Their third-party libraries that try to bridge that gap. Again goes back to this thing earlier, evil enabling to write unsafe code a has allowed I think is Patrick Walton and others. Is basically a couple different crates other that provide C + + interoperability. Somehow. I don't know how they do it because the C + + ABI I don't think a standard. So I don't know actual they are doing. But they are doing something.
                >>  AMAL AHMED: You get the last question.
                >> AUDIENCE:   Should I say my name?
                >>  AMAL AHMED: Sure.
                >> AUDIENCE:   Nikhil Swamy, University of Cambridge, so we have the one thing Felix said was very striking as you know if we get the issue of where someone says I can't understand this error, is our problem. Not there is. But that's also a bit intention the idea of providing powerful new obstructions like you know, say linearity or lifetimes and Rust. Also you know like the ICFP abstractions like monads, where they are sort of famously difficult for new programmers to copy and. So I guess for all three of you, how do you balance this education versus immediate usability trade-off there.
                >>   FELIX KLOCK: I will take a stab first. So my take on this, yes. First of all that is an example of a problem in terms of how do we deal with this? How do you exit provide these sophisticated features in a way that is comprehensive, and preventable to you know, to our audience? I would like to believe that if a feature is really good, it has got some underlying idea that is intuitive. For example, linearity got to my mind, things in the world are linear. I move this around, it is a single object in space. It is not being copied. At least I don't think it is. And so there so many things in the world, that are naturally fitting that model. And so I think if there is an argument that this free copying of things and aliasing of things is an artifact of these computers and you know that the stuff would be able to just copy bits everywhere. But in terms of like users mental models. I think that there is,  like an insight with an example like that where we can say no, this is a resource that is consumable in some sense. And want to sort of have that insight it can help with the teaching process, at least that is my opinion on the matter. It is a matter of identifying what is the way, the metaphor that will really hit home for someone? And the problem is how we find all of those metaphors for every single feature that is out there Mac.
                >>   GREG MORRISETT: Yes I don't have any. [Laughter] what Felix said was great.
                >>   AMAL AHMED: Yes.
                >>   GREG MORRISETT: And then you. On someone like monad and its mistake read their. Yeah. I don't know how many students I have taught claimed you know oh my God I can't use these list parentheses or whatever right? One thing that he about language valuation is how shallow it is in terms of the learning effect. And how much you take a freshman, yes the first time you put them in front of the leg which they will hate it. You take them six months out and you know what? They rewire their own brain and they know how to deal with it. And so--
                >>   FELIX KLOCK:--
                >>   FELIX KLOCK: They may not love it. I see it as someone who is a schema. I did not say the earlier. But I love --spee01 [Laughter].
                >>   GREG MORRISETT: That is just an example when it gets crowded out again and again of oh my God I can't use this because this enterprise is broken as opposed to the little bit that you can learn and is not such a bad and actually is a great interface. Right? Like the HCI world meets the PL world still has not really wrestled with that well. If the answers, sorry.
                >>   AMAL AHMED: Okay with that we should wrap up and thank you so much.
